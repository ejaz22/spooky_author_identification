{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spooky Author Identification\n",
    "\n",
    "https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle\n",
    "\n",
    "Problem : Mulilabel text classification into different classes i.e. EAP HPL MWS\n",
    "\n",
    "Evaluation Metric : Multiclass Log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\Sabeeha\\Desktop\\project\\spooky\\train.csv',index_col='id')\n",
    "test = pd.read_csv(r'C:\\Users\\Sabeeha\\Desktop\\project\\spooky\\test.csv',index_col='id')\n",
    "submission = pd.read_csv(r'C:\\Users\\Sabeeha\\Desktop\\project\\spooky\\sample_submission.csv')\n",
    "#df = pd.concat([train,test], axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author\n",
       "id                                                               \n",
       "id26305  This process, however, afforded me no means of...    EAP\n",
       "id17569  It never once occurred to me that the fumbling...    HPL\n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       EAP       HPL       MWS\n",
       "0  id02310  0.403494  0.287808  0.308698\n",
       "1  id24541  0.403494  0.287808  0.308698\n",
       "2  id00134  0.403494  0.287808  0.308698\n",
       "3  id27757  0.403494  0.287808  0.308698\n",
       "4  id04081  0.403494  0.287808  0.308698"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anlyse submission file to understand what is required\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "id                                                        \n",
       "id02310  Still, as I urged our leaving Ireland with suc...\n",
       "id24541  If a fire wanted fanning, it could readily be ...\n",
       "id00134  And when they had broken down the frail door t...\n",
       "id27757  While I was thinking how I should possibly man...\n",
       "id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29b4a363c08>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target variable analysis\n",
    "train['author'].value_counts(normalize=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the text characters length in test_df and record these\n",
    "test['text_length'] = test['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lable encoding for for target variable\n",
    "d = {'EAP':0, 'HPL':1, 'MWS':2}\n",
    "train['author'] = train['author'].map(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# Identify the stemmer we'll be using to normalize our training data\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "#stop_words = nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process our transcripts by removing numbers, punctuation, and stopwords and then stemming the remaining text\n",
    "\n",
    "# remove digits\n",
    "train['text'] = train['text'].apply(lambda s: re.sub(r'\\d+', '', s))\n",
    "\n",
    "# remove punctuation\n",
    "#train['text'] = train['text'].apply(lambda s: re.sub('[' + string.punctuation + ']', '', s))\n",
    "\n",
    "# lowering and removing punctuation\n",
    "train['text'] = train['text'].apply(lambda x: re.sub(r'[^\\w\\s]','', x.lower()))\n",
    "\n",
    "# perform stemming\n",
    "#train['text'] = train['text'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17621,), (1958,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train , test , split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train['text'], \n",
    "                                                      train['author'], \n",
    "                                                      stratify=train['author'], \n",
    "                                                      random_state=42, \n",
    "                                                      test_size=0.1, \n",
    "                                                      shuffle=True)\n",
    "\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "tfv = TfidfVectorizer(min_df=3,\n",
    "                      max_df=0.95,\n",
    "                      analyzer='word',\n",
    "                      token_pattern=r'\\w{1,}',\n",
    "                      ngram_range=(1, 3), \n",
    "                      use_idf=1,\n",
    "                      smooth_idf=1,\n",
    "                      sublinear_tf=1,\n",
    "                      stop_words = 'english')\n",
    "\n",
    "tfv.fit(list(X_train) + list(X_valid))\n",
    "xtrain_tfv  =  tfv.transform(X_train) \n",
    "xvalid_tfv  = tfv.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758583447741286"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "lr = LogisticRegression()\n",
    "lr.fit(xtrain_tfv,y_train)\n",
    "y_pred = lr.predict_proba(xvalid_tfv)\n",
    "log_loss(y_valid,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5825369372829245"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(xtrain_tfv,y_train)\n",
    "y_pred = clf.predict_proba(xvalid_tfv)\n",
    "log_loss(y_valid,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7915089695471357"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_tfv, y_train)\n",
    "y_pred = clf.predict_proba(xvalid_tfv)\n",
    "log_loss(y_valid,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM after applying TruncatedSVD (LSA)\n",
    "\n",
    "Since SVMs take a lot of time, we will reduce the number of features from the TF-IDF using Singular Value Decomposition before applying SVM. Also, note that before applying SVMs, we must standardize the data by scaling.\n",
    "\n",
    "__Latent Semantic Analysis__\n",
    "\n",
    "In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in sklearn.feature_extraction.text. In that context, it is known as latent semantic analysis (LSA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 : apply SVD\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=120) #120-200 components are good enough for SVM model\n",
    "svd.fit(xtrain_tfv)\n",
    "xtrain_svd = svd.transform(xtrain_tfv)\n",
    "xvalid_svd = svd.transform(xvalid_tfv)\n",
    "\n",
    "# Variance ratio\n",
    "print('Components:\\n', svd.components_)\n",
    "print('Explained variance:\\n', svd.explained_variance_, '\\n')\n",
    "print('Variance ratio: ',np.cumsum(svd.explained_variance_ratio_)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 : apply scaling on the data obtained from SVD. Renaming variable to reuse without scaling.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scl = StandardScaler()\n",
    "scl.fit(xtrain_svd)\n",
    "xtrain_svd_scl = scl.transform(xtrain_svd)\n",
    "xvalid_svd_scl = scl.transform(xvalid_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setp 3 : Fitting a simple SVM\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(C=1.0, probability=True) # since we need probabilities\n",
    "clf.fit(xtrain_svd_scl, y_train)\n",
    "predictions = clf.predict_proba(xvalid_svd_scl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(X_test)\n",
    "df = pd.DataFrame(y_pred,index = test.index,columns= ['MWS','EAP','HPL'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling.\n",
    "\n",
    "Topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body.\n",
    "\n",
    "   - Latent Semantic Indexing Model (LSI) using Truncated SVD\n",
    "   - Latent Dirichlet Allocation (LDA or pLSI)\n",
    "   - Non-Negative Matrix Factorization Model (NMF)\n",
    " \n",
    "__Assumptions__\n",
    "\n",
    "- Documents exhibit multiple topics (but typically not many)\n",
    "- LDA is a probabilistic model with a corresponding generative process\n",
    "- A topic is a distribution over a fixed vocabulary\n",
    "- Only the number of topics is specified in advance\n",
    "\n",
    "        \n",
    "__Metrics__\n",
    " \n",
    "   - Log likelihood (higher is better)\n",
    "   - Perplexity (lower is better)\n",
    " \n",
    "\n",
    "__Latent Semantic Analysis (LSI)__\n",
    "\n",
    "This is effectively just a truncated singular value decomposition of a (very high-rank and sparse) document-term matrix, with only the  r= n_topics largest singular values preserved.\n",
    "\n",
    "__Latent Dirichlet Allocation (proababilistic LSI)__\n",
    "\n",
    "LDA is a probabilistic extension of LSA (also called multinomial PCA), so LDA’s topics can be interpreted as probability distributions over words. These distributions are, just like with LSA, inferred automatically from a training corpus. Documents are in turn interpreted as a (soft) mixture of these topics (again,just like with LSA).\n",
    "\n",
    "Probabilistic, generative model which uncovers the topics latent to a dataset by assigning weights to words in a corpus, where each topic will assign different probability weights to each word. LDA learns the relationships between words, topics, and documents by assuming documents are generated by a particular probabilistic model. LDA is a probabilistic model capable of expressing uncertainty about the placement of topics across texts and the assignment of words to topics,\n",
    "\n",
    "__Non-negative Matrix Factorization (NMF)__ \n",
    "\n",
    "Approximation method that takes an input matrix and approximates the factorization of this matrix into two other matrices, with the caveat that the values in the matrix be non-negative. NMF is a deterministic algorithm which arrives at a single representation of the corpus. For this reason, NMF is often characterized as a machine learning algorithm.\n",
    "\n",
    "\n",
    "__Note__\n",
    "\n",
    "- Like LDA, NMF arrives at its representation of a corpus in terms of something resembling “latent topics”.\n",
    "- better results with NMF (over TF-IDF matrix) than with LDA (with TF matrix).\n",
    "\n",
    "__Multinomial Distribution vs Dirichlet Distribution__\n",
    "\n",
    "Dirichlet distribution is a distribution over all multinomial distributions of the same dimensionality. If a multinomial distribution is a die, a Dirichlet distribution is a dice factory.\n",
    "\n",
    "__Gibbs Sampling__\n",
    "\n",
    "Gibbs sampling is an example of a Markov Chain Monte Carlo (MCMC) technique\n",
    "\n",
    "\n",
    "## Dimensionality Reduction\n",
    "\n",
    "\n",
    "__Principal Component Analysis__\n",
    "\n",
    "an special case of SVD\n",
    "\n",
    "__SVD__\n",
    "\n",
    "Full matrix factorization techinique. Singular Value Decomposition decomposes M into three smaller matrices\n",
    "\n",
    "\n",
    "__truncatedSVD__\n",
    "\n",
    "TruncatedSVD implements a variant of singular value decomposition (SVD) that only computes the  largest singular values, where  is a user-specified parameter. When truncated SVD is applied to term-document matrices (as returned by CountVectorizer or TfidfVectorizer), this transformation is known as latent semantic analysis (LSA), because it transforms such matrices to a “semantic” space of low dimensionality. SVD and truncateSVD does not differ much, since they are based on the same theory that the eigenvectors with the less eigenvalue are discarded.\n",
    "\n",
    "__t-Distributed Stochastic Neighbor Embedding (t-SNE)__\n",
    "\n",
    "Given the high dimension of our tfidf matrix, we need to reduce their dimension using the Singular Value Decomposition (SVD) technique. And to visualize our vocabulary, we could next use t-SNE to reduce the dimension from 50 to 2. t-SNE is more suitable for dimensionality reduction to 2 or 3.\n",
    "\n",
    "t-SNE is a technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. The goal is to take a set of points in a high-dimensional space and find a representation of those points in a lower-dimensional space, typically the 2D plane. It is based on probability distributions with random walk on neighborhood graphs to find the structure within the data. But since t-SNE complexity is significantly high, usually we'd use other high-dimension reduction techniques before applying t-SNE.\n",
    "\n",
    "First, let's take a sample from the both training and testing item's description since t-SNE can take a very long time to execute. We can then reduce the dimension of each vector from to n_components (50) using SVD.\n",
    "\n",
    "__SVD vs NMF__\n",
    "\n",
    "NMF only takes positive values as input while SVD can take both positive and negative values.\n",
    "\n",
    "SVD helps in giving Eigen vectors of the input matrix. The technique is used generally where Eigen Vectors are of interest to us. PCA is one classic example.\n",
    "\n",
    "NMF is another decomposition technique where we try to split the matrix R into the product of two matrices U and V. Our objective here is to get the two matrices U and V, so that their matrix multiplication gives us the matrix R. Here R is typically very very sparse, which is true in a lot of recommender systems. In such cases NMF works better as the missing-values assumption is inbuilt to the algo.\n",
    "\n",
    "In case of SVD, it doesn’t assume anything about mis?sing values. So you need to give some missing value imputation for SVD. This might bring in unnecessary noise. But if your ratings matrix is not too sparse, SVD might produce better results. SVD results are more deterministic compared to that of NMF. That also can play a role in which method you choose.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA is a probabilistic topic modeling approach while NMF is matrix factorization approach\n",
    "# Topic modelling is an unsupervised text mining approach\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "no_features = 1000\n",
    "no_topics = 20\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features,stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model (pLSA)\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95,min_df=2,max_features=no_features,stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(X_train)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, beta_loss='frobenius', init='nndsvd', l1_ratio=0.5, max_iter=200,\n",
       "    n_components=20, random_state=1, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NMF\n",
    "nmf = NMF(n_components=no_topics,random_state=1,alpha=.1,l1_ratio=.5,init='nndsvd')\n",
    "nmf.fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='online', learning_offset=50.0,\n",
       "                          max_doc_update_iter=100, max_iter=5,\n",
       "                          mean_change_tol=0.001, n_components=20, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, max_iter=5, \n",
    "                                learning_method='online', \n",
    "                                learning_offset=50.,random_state=0)\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hleper function to Display Topics\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic:\",idx, \" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 eyes old house left heard far place men felt room\n",
      "Topic: 1 said dupin let friend dear yes sir sure thousand altogether\n",
      "Topic: 2 did appear come return believe perdita feel understand wish mr\n",
      "Topic: 3 man old young dead animal business god sat excellent small\n",
      "Topic: 4 time spent space short mean passed high year occupied reached\n",
      "Topic: 5 heart love soul hope affection dear words joy child nature\n",
      "Topic: 6 saw looked light moon went form face felt feet waves\n",
      "Topic: 7 little difficulty truth way age gave degree trouble car means\n",
      "Topic: 8 say mean truth course general dont strange dare just possible\n",
      "Topic: 9 great measure god difficulty length took degree distance suffered stone\n",
      "Topic: 10 like looked old ye light sleep face water look earth\n",
      "Topic: 11 thought heard felt unknown knew really possible mind moment soul\n",
      "Topic: 12 know dont tell matter certain think right just gone fact\n",
      "Topic: 13 things strange sea earth knew says told speak state world\n",
      "Topic: 14 thing wonder terrible world occurred human impossible somewhat horror quite\n",
      "Topic: 15 life death world hope alas pain spent spirit existence dream\n",
      "Topic: 16 night day passed sleep late slept hours home morning went\n",
      "Topic: 17 came men light spirit street home door moon sleep head\n",
      "Topic: 18 shall die seek feel meet hope appear success present lost\n",
      "Topic: 19 long ago hours feet end read appeared narrow black line\n"
     ]
    }
   ],
   "source": [
    "# for NMF\n",
    "display_topics(nmf, tfidf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 seen away looked body hope turned thousand entered change dream\n",
      "Topic: 1 did good course street sea object large times true dear\n",
      "Topic: 2 half air appeared horror scene morning second terrible countenance memory\n",
      "Topic: 3 men world hand friend young wild thoughts vast merely arms\n",
      "Topic: 4 soul moon called nearly attention remained led child age green\n",
      "Topic: 5 eyes things room knew strange think mind known near present\n",
      "Topic: 6 long came length spirit hours person brought continued poor time\n",
      "Topic: 7 man come soon dark city water father power passed taken\n",
      "Topic: 8 said time door earth longer reason work west read family\n",
      "Topic: 9 shall house moment end feel white suddenly dreams speak country\n",
      "Topic: 10 old know words years went matter truth believe knowledge houses\n",
      "Topic: 11 night like let deep feet mr general fell home floor\n",
      "Topic: 12 life thought head open small lay tears eyes joy ground\n",
      "Topic: 13 light black right people ancient hands means grew window appearance\n",
      "Topic: 14 heard thing having make voice look perdita possible portion scarcely\n",
      "Topic: 15 say idea manner sound beneath better sense land mere account\n",
      "Topic: 16 felt nature new heart told dead point lost spoke quite\n",
      "Topic: 17 day far love way human took gave began return stood\n",
      "Topic: 18 death place fear saw hour doubt character adrian misery heaven\n",
      "Topic: 19 great little left raymond just form kind eye face certain\n"
     ]
    }
   ],
   "source": [
    "# for LDA\n",
    "display_topics(lda, tf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Topic-Keyword Matrix\n",
    "df_topic_keywords = pd.DataFrame(lda.components_)\n",
    "df_topic_keywords.columns = tf_vectorizer.get_feature_names()\n",
    "df_topic_keywords.index = [\"Topic\" + str(i) for i in range(lda.n_components)] # term weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accident</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>added</th>\n",
       "      <th>admiration</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>written</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>68.555695</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050008</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050018</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>51.186990</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050197</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>88.305796</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050005</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050006</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050005</td>\n",
       "      <td>42.082574</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>0.050001</td>\n",
       "      <td>62.980701</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050006</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>...</td>\n",
       "      <td>283.117823</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050006</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>206.698440</td>\n",
       "      <td>0.050003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050005</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050011</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>52.554394</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             able    absence  absolutely  accident   account       act  \\\n",
       "Topic0  68.555695   0.050002    0.050008  0.050001  0.050018  0.050001   \n",
       "Topic1   0.050001   0.050002    0.050005  0.050001  0.050002  0.050004   \n",
       "Topic2   0.050001   0.050004    0.050002  0.050001  0.050001  0.050005   \n",
       "Topic3   0.050001  62.980701    0.050001  0.050001  0.050006  0.050001   \n",
       "Topic4   0.050001   0.050001    0.050003  0.050001  0.050003  0.050005   \n",
       "\n",
       "           action   actually     added  admiration  ...       world     write  \\\n",
       "Topic0   0.050001  51.186990  0.050002    0.050001  ...    0.050197  0.050001   \n",
       "Topic1   0.050001   0.050006  0.050001    0.050002  ...    0.050001  0.050001   \n",
       "Topic2  42.082574   0.050003  0.050001    0.050002  ...    0.050002  0.050001   \n",
       "Topic3   0.050001   0.050001  0.050001    0.050003  ...  283.117823  0.050001   \n",
       "Topic4   0.050001   0.050011  0.050001    0.050002  ...    0.050001  0.050001   \n",
       "\n",
       "         written        ye       year      years    yellow       yes  \\\n",
       "Topic0  0.050002  0.050003  88.305796   0.050009  0.050002  0.050003   \n",
       "Topic1  0.050001  0.050001   0.050002   0.050002  0.050001  0.050001   \n",
       "Topic2  0.050001  0.050001   0.050001   0.050002  0.050001  0.050002   \n",
       "Topic3  0.050002  0.050002   0.050001   0.050002  0.050006  0.050003   \n",
       "Topic4  0.050002  0.050001   0.050001  52.554394  0.050003  0.050001   \n",
       "\n",
       "             young     youth  \n",
       "Topic0    0.050003  0.050002  \n",
       "Topic1    0.050002  0.050002  \n",
       "Topic2    0.050002  0.050001  \n",
       "Topic3  206.698440  0.050003  \n",
       "Topic4    0.050002  0.050003  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing LDA with pyLDAvis\n",
    "\n",
    "__Saliency:__ a measure of how much the term tells you about the topic.\n",
    "\n",
    "__Relevance:__ a weighted average of the probability of the word given the topic and the word given the topic normalized by the probability of the topic.\n",
    "\n",
    "The size of the bubble measures the importance of the topics, relative to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el110603613073526892202609\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el110603613073526892202609_data = {\"mdsDat\": {\"x\": [0.15910930855582078, 0.17463739757929136, -0.10004406092321338, -0.058946988956650445, -0.14018120483343746, -0.05377730843151681, 0.21162885219389052, 0.19006776134330716, -0.09451658453870687, 0.11122434557441208, 0.18999030765872496, -0.07721199356900775, -0.03084698006076923, -0.05026929539056321, -0.026964986875955818, -0.0642957528379315, -0.052252030342917824, -0.12907533511642774, -0.098614055139045, -0.05966139588930338], \"y\": [0.09340747674391871, 0.0733398939778655, 0.21893637621607642, 0.11107547452515132, 0.24887214764660512, -0.022395210533972983, 0.006021986594742684, 0.007285065886012901, -0.14078699405833903, 0.030859830805312922, -0.048675994814179314, -0.17070034749728286, -0.043851121440242655, -0.09123136380466175, -0.09377700246162213, -0.07613653156483284, -0.09239555822557723, 0.15524983157457664, -0.08040110996261043, -0.0846968496069393], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [6.966426591982754, 6.490817615837775, 6.177564633402038, 5.732043891163697, 5.434529346314625, 5.214931756626594, 5.212180745412679, 5.043141488835573, 4.972870686124704, 4.897432792852881, 4.806899172305834, 4.7305589645421104, 4.678422820980424, 4.610952888159161, 4.5957244391499685, 4.592150876010241, 4.407930446269502, 4.0327912443116976, 3.9276592123788907, 3.4749703873388347]}, \"tinfo\": {\"Term\": [\"did\", \"said\", \"man\", \"life\", \"great\", \"long\", \"night\", \"day\", \"old\", \"thought\", \"like\", \"say\", \"little\", \"eyes\", \"death\", \"heard\", \"thing\", \"came\", \"men\", \"felt\", \"shall\", \"far\", \"house\", \"know\", \"left\", \"light\", \"world\", \"things\", \"love\", \"hand\", \"man\", \"come\", \"soon\", \"city\", \"dark\", \"water\", \"power\", \"taken\", \"state\", \"wind\", \"close\", \"case\", \"happiness\", \"youth\", \"arm\", \"late\", \"affection\", \"loved\", \"entirely\", \"use\", \"beloved\", \"minutes\", \"thou\", \"drew\", \"atmosphere\", \"bring\", \"immediate\", \"creatures\", \"thy\", \"tree\", \"father\", \"passed\", \"days\", \"despair\", \"sun\", \"old\", \"place\", \"night\", \"let\", \"feet\", \"mr\", \"deep\", \"general\", \"fell\", \"home\", \"floor\", \"sleep\", \"question\", \"blood\", \"shadow\", \"subject\", \"ill\", \"remember\", \"lips\", \"lady\", \"months\", \"clear\", \"threw\", \"understand\", \"evidently\", \"south\", \"ocean\", \"influence\", \"queer\", \"apparent\", \"mountains\", \"ship\", \"like\", \"low\", \"reached\", \"came\", \"earth\", \"time\", \"room\", \"knew\", \"think\", \"known\", \"present\", \"fact\", \"unknown\", \"expression\", \"things\", \"filled\", \"difficulty\", \"wide\", \"hill\", \"opened\", \"horrible\", \"pain\", \"ears\", \"asked\", \"making\", \"calm\", \"brief\", \"suffered\", \"tomb\", \"seized\", \"corner\", \"oclock\", \"wholly\", \"monstrous\", \"limbs\", \"happened\", \"eyes\", \"strange\", \"set\", \"oh\", \"near\", \"town\", \"feeling\", \"period\", \"sat\", \"mind\", \"natural\", \"happy\", \"day\", \"far\", \"love\", \"way\", \"human\", \"took\", \"gave\", \"began\", \"return\", \"stood\", \"beauty\", \"trees\", \"stone\", \"hideous\", \"river\", \"cause\", \"mountain\", \"surface\", \"thrown\", \"narrow\", \"society\", \"suppose\", \"forms\", \"marble\", \"rise\", \"listened\", \"ghastly\", \"perfect\", \"rapidly\", \"slowly\", \"given\", \"high\", \"children\", \"spot\", \"near\", \"great\", \"left\", \"just\", \"raymond\", \"form\", \"kind\", \"eye\", \"evening\", \"god\", \"mother\", \"evil\", \"terror\", \"windows\", \"distance\", \"impossible\", \"hills\", \"hardly\", \"cast\", \"sister\", \"condition\", \"objects\", \"rendered\", \"pass\", \"approached\", \"persons\", \"plain\", \"glass\", \"thee\", \"reality\", \"animal\", \"little\", \"face\", \"certain\", \"presence\", \"mind\", \"saw\", \"shall\", \"house\", \"moment\", \"end\", \"white\", \"suddenly\", \"dreams\", \"speak\", \"country\", \"word\", \"replied\", \"idris\", \"silence\", \"imagination\", \"greater\", \"sir\", \"arose\", \"early\", \"red\", \"closed\", \"native\", \"stars\", \"attempt\", \"discovery\", \"breath\", \"language\", \"whilst\", \"woods\", \"departed\", \"week\", \"feel\", \"till\", \"seen\", \"away\", \"looked\", \"body\", \"hope\", \"turned\", \"thousand\", \"entered\", \"change\", \"dream\", \"necessary\", \"leave\", \"short\", \"died\", \"observed\", \"year\", \"especially\", \"live\", \"resolved\", \"wife\", \"paper\", \"party\", \"easily\", \"height\", \"turn\", \"able\", \"alive\", \"real\", \"seek\", \"passage\", \"like\", \"time\", \"long\", \"length\", \"spirit\", \"hours\", \"person\", \"brought\", \"continued\", \"poor\", \"discovered\", \"care\", \"grief\", \"circumstances\", \"darkness\", \"proceeded\", \"mad\", \"entire\", \"girl\", \"born\", \"ceased\", \"extent\", \"supposed\", \"elizabeth\", \"sad\", \"ran\", \"write\", \"vision\", \"different\", \"horizon\", \"marked\", \"giving\", \"came\", \"possessed\", \"fellow\", \"london\", \"time\", \"felt\", \"new\", \"told\", \"dead\", \"point\", \"lost\", \"spoke\", \"nature\", \"quite\", \"view\", \"past\", \"gone\", \"held\", \"existence\", \"self\", \"england\", \"followed\", \"lived\", \"broken\", \"order\", \"public\", \"apparently\", \"fancy\", \"answer\", \"later\", \"health\", \"exceedingly\", \"peace\", \"taking\", \"sufficiently\", \"regard\", \"heart\", \"tell\", \"immediately\", \"know\", \"words\", \"went\", \"matter\", \"truth\", \"believe\", \"knowledge\", \"houses\", \"letter\", \"purpose\", \"various\", \"altogether\", \"fully\", \"line\", \"got\", \"instant\", \"dr\", \"ago\", \"book\", \"dont\", \"forgotten\", \"expected\", \"fine\", \"remembered\", \"conversation\", \"english\", \"carried\", \"amidst\", \"innsmouth\", \"added\", \"gentleman\", \"years\", \"old\", \"sight\", \"time\", \"said\", \"reason\", \"work\", \"west\", \"read\", \"family\", \"feelings\", \"returned\", \"walls\", \"friends\", \"corpse\", \"save\", \"strength\", \"woman\", \"plague\", \"delight\", \"caused\", \"companion\", \"longer\", \"struck\", \"faint\", \"business\", \"fresh\", \"spring\", \"features\", \"rain\", \"dupin\", \"spirits\", \"palace\", \"nervous\", \"door\", \"earth\", \"looking\", \"time\", \"did\", \"good\", \"course\", \"street\", \"object\", \"large\", \"times\", \"true\", \"dear\", \"best\", \"chamber\", \"usual\", \"met\", \"events\", \"appear\", \"says\", \"sufficient\", \"road\", \"machine\", \"deserted\", \"need\", \"island\", \"succeeded\", \"farther\", \"crowd\", \"building\", \"sent\", \"notice\", \"minute\", \"success\", \"sea\", \"visible\", \"death\", \"fear\", \"doubt\", \"hour\", \"character\", \"adrian\", \"misery\", \"heaven\", \"die\", \"somewhat\", \"grave\", \"formed\", \"beautiful\", \"boat\", \"ye\", \"visit\", \"hung\", \"fate\", \"castle\", \"beings\", \"shore\", \"progress\", \"fall\", \"sole\", \"pale\", \"hopes\", \"danger\", \"dared\", \"fearful\", \"tall\", \"place\", \"saw\", \"light\", \"black\", \"right\", \"people\", \"ancient\", \"hands\", \"means\", \"grew\", \"window\", \"appearance\", \"wall\", \"rest\", \"sky\", \"bed\", \"table\", \"single\", \"round\", \"kept\", \"box\", \"going\", \"books\", \"ordinary\", \"mouth\", \"cut\", \"spent\", \"forest\", \"cried\", \"north\", \"flowers\", \"act\", \"saw\", \"heard\", \"thing\", \"having\", \"make\", \"voice\", \"look\", \"perdita\", \"possible\", \"portion\", \"scarcely\", \"sought\", \"singular\", \"hair\", \"force\", \"main\", \"yes\", \"slight\", \"vain\", \"sort\", \"perceive\", \"story\", \"afterward\", \"gold\", \"endeavoured\", \"following\", \"despite\", \"forced\", \"behold\", \"dog\", \"upper\", \"blue\", \"gentle\", \"sweet\", \"living\", \"door\", \"head\", \"life\", \"thought\", \"open\", \"small\", \"tears\", \"joy\", \"sounds\", \"frame\", \"want\", \"wished\", \"alas\", \"fallen\", \"passion\", \"design\", \"frightful\", \"occurred\", \"uncle\", \"moved\", \"bent\", \"huge\", \"solitude\", \"curiosity\", \"winter\", \"failed\", \"impression\", \"faces\", \"aspect\", \"fled\", \"disease\", \"instance\", \"head\", \"lay\", \"ground\", \"sure\", \"eyes\", \"heart\", \"men\", \"world\", \"hand\", \"friend\", \"young\", \"wild\", \"thoughts\", \"vast\", \"arms\", \"wonder\", \"wish\", \"forth\", \"merely\", \"odd\", \"received\", \"excited\", \"coming\", \"windsor\", \"desire\", \"absence\", \"summer\", \"sympathy\", \"help\", \"number\", \"intense\", \"dare\", \"weight\", \"shewed\", \"rich\", \"utter\", \"peculiar\", \"say\", \"idea\", \"manner\", \"sound\", \"beneath\", \"better\", \"sense\", \"land\", \"mere\", \"account\", \"degree\", \"really\", \"escape\", \"figure\", \"placed\", \"lovely\", \"does\", \"effect\", \"bore\", \"lord\", \"perceived\", \"covered\", \"music\", \"gilman\", \"evidence\", \"evident\", \"increased\", \"ideas\", \"distinct\", \"started\", \"common\", \"little\", \"mind\", \"half\", \"air\", \"appeared\", \"horror\", \"scene\", \"morning\", \"second\", \"terrible\", \"countenance\", \"memory\", \"cold\", \"finally\", \"changed\", \"position\", \"tried\", \"tale\", \"simple\", \"mean\", \"utterly\", \"art\", \"remain\", \"ice\", \"forever\", \"courage\", \"brain\", \"sentiment\", \"slept\", \"cloud\", \"individual\", \"gradually\", \"motion\", \"called\", \"moon\", \"nearly\", \"attention\", \"remained\", \"led\", \"child\", \"age\", \"green\", \"space\", \"secret\", \"steps\", \"silent\", \"arrived\", \"outside\", \"company\", \"waters\", \"gods\", \"madame\", \"st\", \"apartment\", \"mentioned\", \"watched\", \"greatest\", \"search\", \"carefully\", \"fixed\", \"pocket\", \"example\", \"bodies\", \"soul\", \"years\"], \"Freq\": [633.0, 630.0, 658.0, 492.0, 484.0, 451.0, 489.0, 454.0, 528.0, 397.0, 542.0, 372.0, 477.0, 483.0, 342.0, 324.0, 322.0, 400.0, 311.0, 323.0, 321.0, 329.0, 316.0, 302.0, 312.0, 288.0, 283.0, 321.0, 296.0, 268.0, 657.7811519946415, 275.3547438196587, 233.7744775418325, 196.3392121884809, 196.97692170513466, 164.363406286362, 145.5528450473248, 141.76939920175897, 126.53740771861276, 117.71765610082602, 116.94693891057668, 114.77349271234993, 109.36829031058389, 90.2249685052171, 87.80208612978554, 84.47807205912322, 83.27388005670375, 81.47450169575718, 80.59746790553527, 78.9897966825819, 75.30661845981223, 74.54162881288154, 70.37756097289343, 68.56418265400995, 67.42102109240363, 66.45918645628826, 66.40386485154548, 60.67990543896591, 60.23315029027692, 59.671767046716226, 156.59744645933517, 145.2468175230097, 139.9363114367153, 91.90659124966183, 89.57671391590367, 138.66836493049334, 74.17364999256075, 488.68591117083514, 248.30731505431038, 166.19216825607813, 162.97126199820758, 167.11826426243448, 143.83833416407782, 140.6532528812428, 137.93598255427165, 124.25380730012223, 121.48354575071403, 111.80177240010102, 102.80195064439592, 95.69004160338315, 94.47307229763601, 91.06151712522544, 87.8470138067549, 86.49814722599766, 86.37044224637488, 82.9017724876652, 68.87506766482387, 67.17996517247576, 67.03218649628366, 66.32762772119199, 66.33545872196866, 64.89540624679758, 64.54697921037268, 61.210904409918, 60.60237312188122, 59.53106838331102, 58.498065755652114, 439.4859313119116, 88.36892188875618, 76.32817041809481, 92.55763235818047, 77.58887792898103, 66.16963921523566, 255.37654509753432, 231.20003549283763, 166.91604105899302, 162.6132017713194, 140.98440526818834, 133.17414589343082, 108.13274825120551, 95.81219209923451, 317.9968263882522, 92.38335816108577, 84.67380299422457, 83.83127628501299, 75.15644351309838, 76.37831063188264, 74.8773756230227, 70.33203826243263, 67.52534753822144, 67.25692970126002, 65.13366488942897, 63.46347724999221, 55.70030619513897, 55.36991322403942, 53.19360186909443, 52.08559543274585, 50.572468479188814, 49.25363730969056, 48.54160028320484, 48.35241623521715, 47.9764600561014, 47.55441465475144, 373.33016234870973, 200.15561558796577, 105.07454248580252, 103.17530745604297, 152.8894700435998, 97.33083335961841, 84.6773691205629, 85.22678249893404, 83.62052434390773, 164.6492543484401, 66.53478691141089, 66.68023229801199, 453.781108506886, 328.6789848798659, 295.47690434667993, 263.6492713102264, 245.4765806785237, 206.57081894392303, 200.98093638192466, 156.95733094189396, 146.06561720140007, 144.2956169589524, 135.42568578700894, 124.26092429609862, 110.94463141568767, 100.94004807682018, 99.11857958621285, 89.39176839563002, 80.52322529635522, 76.28456975786541, 72.04755662372621, 66.1930837578939, 65.27559958666274, 59.392930863221196, 57.32928835420843, 55.70629940002159, 54.97025016234857, 51.781371280289314, 48.86811648309726, 48.49347235545441, 47.21561545240922, 46.04841463965265, 98.06989335101369, 129.89637174036594, 61.30015517868363, 61.086351300279034, 60.510728412910346, 483.4750395289692, 312.0247274785446, 197.2590793747184, 218.02278546726748, 173.38510625657395, 167.33563576500998, 148.77669806284473, 110.6871566219767, 107.31909741454464, 107.25008165340003, 104.20026008886019, 96.15063383385736, 88.58622775784161, 84.35992397315785, 82.62586548250788, 77.96218500610068, 72.61244559369797, 83.94218210188477, 70.05762704939087, 61.86205139097034, 60.20514530903911, 60.037981018955946, 58.25044658281754, 56.81856511884157, 55.51954510413805, 54.40855165925993, 51.2989083693373, 50.914716341048816, 50.18333595651949, 49.65978842955998, 399.1117102837677, 136.8062591672298, 131.70243510350852, 57.98123141146775, 75.67143105500823, 73.73897707534336, 320.8243645474087, 315.40437708746634, 218.5233093328412, 189.8824745690894, 136.24842337049267, 136.0718065894041, 134.48488735524728, 133.01881614862964, 131.54519148756378, 128.3207327092089, 108.5761223730522, 104.52396039090765, 99.18597087434617, 95.67067718818852, 93.14918080120076, 88.03523247078824, 82.57779015717388, 80.04974339360936, 74.44894962459027, 71.5441903866405, 65.4503436464979, 65.29551456793014, 63.37094574538864, 58.799996187196, 58.285895390276735, 58.04390332299624, 54.47997202244707, 54.36726146428955, 50.07456549051376, 48.600764063604096, 141.5508315307537, 65.12257872895908, 251.98775410325584, 251.164862185095, 194.79863089456538, 190.19504831746855, 164.80849627765016, 161.82543538537251, 156.04758936445026, 133.45532385464017, 126.44843720618499, 120.34495603509302, 98.15206535598999, 97.07296914629242, 96.58114577578846, 111.06990748742942, 94.90016294710723, 85.59677607268637, 82.29019023280816, 77.77335341471534, 76.87508507679502, 74.23015084328733, 73.59726196192308, 70.85200916380018, 70.66173173358185, 70.01923633943174, 67.70852733919294, 66.45256261732786, 63.72141888035166, 60.753773288269144, 59.26957489048715, 58.82369623204881, 101.56918307172423, 99.10969822771419, 450.6399268989267, 248.28319743990477, 178.90392891566896, 152.77209724140675, 148.18578893543202, 145.4587304602607, 126.9208501908734, 123.55319435137113, 97.68071270079271, 89.69351948464526, 85.7588897558218, 83.99066183390264, 83.82405282475443, 80.36594941753529, 72.4415295984322, 72.49844254105258, 70.83801105700816, 65.13301971379447, 62.01444762021375, 61.637192409470195, 60.82230387529927, 59.89081226018662, 56.23307030890248, 55.013043747436384, 54.44705429865763, 53.57112926976288, 52.78780642619043, 50.79441416194428, 47.89428674238157, 47.12677988377173, 307.2657372659737, 69.40435356222392, 71.82072703717985, 63.89857696994716, 99.61917510677937, 322.35219905302034, 233.2026333595436, 190.15858988665266, 174.60043682604933, 172.5917911217779, 157.3913895429433, 156.418579497228, 251.65432989940177, 125.19423122292395, 122.75036534860963, 118.31120570176256, 115.24967806846962, 101.18463725739572, 96.83597258263153, 91.78894115673108, 89.60490833030843, 88.27605397149367, 81.09930318484678, 77.42374774638522, 74.8178622515045, 73.10505503753859, 72.30095069297835, 70.19299899719715, 64.49490741390882, 62.79613918723601, 61.22552402416174, 60.232618985169374, 59.51524028844126, 57.057065587792934, 56.92125151328465, 58.63682639771611, 213.66406886999803, 115.14143111345577, 82.00079633784677, 301.1366980163591, 254.46910994960646, 187.2301426497961, 181.5867193060447, 130.39059549390117, 123.2263693738739, 99.41752905002558, 98.82398212159747, 92.62827851533584, 91.69683708112694, 84.39521778621477, 84.00854528808512, 83.21525398871958, 82.56169520162483, 75.18454457912397, 75.12172654071748, 72.06980626935281, 66.7729453440406, 66.97976550755537, 65.30788220112035, 62.73457936930231, 60.4673135127532, 57.008047663983184, 57.05688248892361, 56.238979805279676, 55.24927223170468, 54.34890470233373, 52.7885129233793, 52.12048538789428, 51.32684482209682, 58.559404687742266, 251.67367190896215, 388.5702846202244, 75.80129642261024, 68.64098886371544, 629.4217904797646, 131.4197108209347, 130.41731989124307, 125.78032400408196, 114.70299225655191, 112.83107671864454, 109.85126307630175, 100.50536726172217, 99.23917256149633, 96.28303819536887, 86.31760036544337, 82.03379947754182, 81.42121464300918, 80.51559704163488, 79.41859362821047, 78.83047363130984, 74.26214002137544, 73.91386529620767, 131.50758254103377, 71.37394009536916, 68.29577848255218, 66.64951090785715, 65.23286052366183, 62.27843772169366, 61.356359210442506, 59.908475719558716, 55.03748701740996, 47.13943291865522, 46.75785213063369, 44.49797474364025, 197.50042238981587, 194.20716279726784, 83.06771123025749, 207.92242873082023, 632.2758873319503, 237.00958589972092, 178.74356334198356, 167.61697592467786, 142.71207322995465, 138.93417030852206, 138.3766200516968, 129.3469717549447, 119.25678858628315, 102.8813702067808, 99.34610871760022, 85.6671382899023, 76.89429164683605, 70.04024975522125, 69.334614115218, 68.52848941738624, 64.13285937614467, 64.0085118369011, 62.990275343783686, 59.8993702994188, 56.778743014059025, 55.260576069835686, 53.63996389252524, 51.72010433404506, 51.38383777730725, 51.38307933286638, 51.33236247875906, 50.926892345533474, 49.53062257065599, 47.85127245544779, 153.11149881509013, 57.66287015158128, 341.2151655435221, 205.36772572903374, 144.29549111093345, 153.4482397626829, 115.13646694785326, 112.20861405517019, 96.18955784491516, 94.26173441700205, 89.00625013939388, 88.90496693200222, 86.35344478923507, 87.01658290454809, 82.85054562654686, 77.02333907654905, 74.2351291798043, 74.17418133160108, 72.99199286056866, 65.70972097329312, 65.37519333151236, 64.98800257960569, 64.00679470893606, 63.2769006255628, 62.4618112804395, 61.52473535329637, 63.04196996190665, 58.89457623407823, 58.66029504164549, 58.5913064261469, 57.90885998676246, 57.70179285703958, 227.54554894621248, 179.65094166132306, 287.69899121423487, 184.22513863598635, 168.9254476218775, 157.9317211203208, 153.41378269167956, 149.29901182569986, 146.74791796002341, 130.0774687362801, 117.02062199902241, 111.75494523645557, 109.8271820494106, 108.30518627958848, 96.42536992597158, 87.53877719266433, 82.73678630466084, 80.53209807659839, 79.65025955048957, 78.82244277037758, 76.90971021961653, 73.40541418654772, 73.25384072724499, 72.51199073909505, 69.61837384885312, 67.3911951445558, 64.47293117905382, 61.35309232078614, 61.157875667841054, 77.6764996298266, 58.94254282178693, 58.61926222585137, 65.36628448100228, 323.9763814030605, 321.13287038493814, 263.1444890051712, 261.46546684241923, 252.04679575016712, 172.7596352267752, 145.00417032966055, 129.92757068063824, 99.01785056743084, 90.65841566557624, 82.6939608595573, 81.08553966885543, 76.6750519055034, 79.931708598815, 70.01994031686583, 69.81953908289913, 68.90031539951627, 63.40490462423673, 63.190552631268794, 63.15287050988869, 62.32057084835628, 58.16359059673964, 56.69445713329316, 51.559951344993465, 51.303984105247885, 48.8813623033035, 48.69613550042857, 48.12176671450617, 47.16396177265065, 46.2905981228427, 68.18408951117846, 87.88692594943232, 64.73147252778216, 64.24184612692159, 61.50539814750504, 58.056070056730555, 491.65129196034815, 396.73760874361966, 196.2718162664719, 192.72671535559377, 123.21918504663937, 89.47348693598107, 82.39622452591593, 74.56063540791199, 68.741487554164, 67.25774355754345, 66.38395787216935, 65.15494642023968, 62.05714152599601, 61.97329964987928, 59.36506479366357, 58.70299933610222, 57.469884457358056, 57.181957977911885, 54.80409763193004, 54.070751559645444, 54.12044010473791, 52.71058346200795, 52.43514573038021, 51.07946401466651, 49.697663887223385, 48.31853428435035, 47.65197044206201, 47.347496623839945, 46.50442741878425, 46.19752793153077, 215.7532466464962, 132.89591687557947, 83.12215718726202, 74.85864232954161, 109.03842368691835, 69.17086176006521, 310.71885744220725, 283.0006251356296, 267.81953506359565, 261.73879982786485, 206.6128754868907, 149.998063565237, 132.69358901090155, 119.69629071500673, 100.39168850250756, 99.87480435374, 97.62292688984613, 92.07731320032194, 110.94690109158209, 84.65466091207007, 83.02917089921557, 76.73257745717129, 75.30440100395997, 70.18258122331186, 67.67815780306846, 62.95463004918234, 59.29168459988584, 59.05611689667861, 57.66001551566268, 57.64775338608099, 57.49185130547072, 55.04976176390354, 52.24616384740468, 51.743186750141746, 51.60690455358039, 50.8174993180437, 52.85739069841739, 371.99790049318875, 184.02945140933903, 163.66390388825377, 152.8355079099398, 136.176636310774, 135.1496758300658, 124.65782328487406, 107.40694692276423, 105.90001519766707, 103.92536372630224, 95.98930739306566, 90.46102800799271, 86.62127750820638, 85.40161484973129, 82.96761717878098, 80.5395448830955, 79.13950383519284, 74.007359076482, 71.00268440338006, 67.36543702740332, 66.22896664235854, 65.27388006293728, 64.10135580880593, 61.62420521612553, 59.53437423447629, 53.8105907923367, 53.641360972012365, 52.65182291174805, 52.59981460875105, 51.80944824597123, 57.884659868004796, 77.08968345904862, 55.189136383020866, 252.3903438518395, 218.62785423146713, 205.42914371530523, 194.8973378262876, 162.70498781052518, 162.63522591491085, 145.54402091070332, 137.93930056029433, 119.2169948205959, 100.91582041284673, 99.16457592775687, 82.66837615485466, 82.16980125183176, 77.6769722027096, 74.60750265647525, 72.60095822907442, 71.56326403595989, 70.9357280785993, 68.59427196835688, 67.0708796316728, 65.14303222162187, 63.7041821851573, 63.61205411234455, 60.959921289448346, 60.67649282578392, 51.314832689875914, 49.97388360968358, 48.198065533097164, 47.46374366425187, 45.80066845207458, 54.28844488163704, 162.4259368532289, 163.61853809856305, 153.08005870497902, 142.25685608504526, 135.18879839615104, 119.8400023214461, 119.8189164006584, 115.66843438985968, 106.81503810202068, 106.33233159693566, 102.89006579016039, 87.33405171151055, 80.97900534794675, 77.04460684694442, 76.9780932387896, 75.63374067520367, 68.64859726115824, 68.01398512185804, 65.02913601021238, 63.98910633156009, 61.660734024811255, 66.13811943179277, 55.86875231775956, 54.44830852440897, 53.58938414247221, 51.061516133656696, 49.226100294657975, 48.82163804141802, 47.13460939283188, 46.978433392943906, 183.21715749878248, 56.224529276029344], \"Total\": [633.0, 630.0, 658.0, 492.0, 484.0, 451.0, 489.0, 454.0, 528.0, 397.0, 542.0, 372.0, 477.0, 483.0, 342.0, 324.0, 322.0, 400.0, 311.0, 323.0, 321.0, 329.0, 316.0, 302.0, 312.0, 288.0, 283.0, 321.0, 296.0, 268.0, 658.7468518855401, 276.2972429150807, 234.71763147583553, 197.28278597488418, 197.92919689204422, 165.30569930113293, 146.5103304235744, 142.71174983604627, 127.47966991784345, 118.66123419457654, 117.88931879291752, 115.71577760694332, 110.32131494418095, 91.16743890943329, 88.74513040965665, 85.42032087188672, 84.2162110619912, 82.41700091008803, 81.53970566287869, 79.9320431977582, 76.24887342078152, 75.48388428628542, 71.3372247869637, 69.50651324931694, 68.36331192797779, 67.40146966897483, 67.34616175773148, 61.6221822011961, 61.17539688302865, 60.614025560783574, 192.3331764669981, 191.5323742504758, 201.73148856625141, 114.88126632048969, 140.63427998282452, 528.2976135843995, 315.6934206642845, 489.6338327794095, 249.25099147811994, 167.13418190873625, 163.9132532497486, 168.0937988062049, 144.7811520881811, 141.59528390944897, 138.8780191745263, 125.19584126821866, 122.42555280454324, 112.74382768377566, 103.74397537985433, 96.63296995292283, 95.41509161104824, 92.0035324638275, 88.79139043584479, 87.440149127027, 87.31245178566402, 83.84381411025977, 69.8170670246263, 68.12207139053938, 67.97431076122574, 67.2696202110669, 67.27803969812501, 65.8374095465242, 65.48897956135299, 62.15289484935936, 61.54437272754578, 60.47313082605024, 59.44022412536231, 542.1747897161201, 110.25808732862096, 101.63090456709423, 400.71628472458184, 272.688767197776, 605.8592024168141, 256.32165602910754, 232.14218091827132, 167.85850521748858, 163.56125429980486, 141.92843195353132, 134.11633935160293, 109.0751239888643, 96.7543538136748, 321.23431492081494, 93.33716150434812, 85.61595116021584, 84.77341724177603, 76.098579355048, 77.33923956849497, 75.81954308809144, 71.27594363209285, 68.46749972148345, 68.19909738743068, 66.0811971086172, 64.40567022409292, 56.642483149753645, 56.31204680894392, 54.13575521223781, 53.02781345223377, 51.51480783143191, 50.19584836737736, 49.48379986667869, 49.29463274308853, 48.918851105476456, 48.49657113034568, 483.2617729228556, 249.06616616576196, 123.23295896736067, 122.30632969250163, 214.299486465396, 122.54750971936885, 106.29245173732374, 110.45197846777972, 107.94931485803413, 344.01125605130534, 93.23236551651749, 103.21352999625893, 454.72250738754684, 329.62171945996073, 296.4183207601445, 264.59572720856863, 246.417707132924, 207.5125021208341, 201.9220758648397, 157.8986103969858, 147.0068607957149, 145.2367851808409, 136.36702157773965, 125.20207959404014, 111.88575307854605, 101.88116941108919, 100.0598015746693, 90.33288390463848, 81.46434462113051, 77.22572355917202, 72.98878249037693, 67.13420603840558, 66.2167231142082, 60.33411139839004, 58.270445419078264, 56.650830132896026, 55.930091681513886, 52.72249330667456, 49.80925701040879, 49.43460726732117, 48.156787060893116, 46.99002242044048, 120.06524755529674, 171.95766181170555, 82.53681144568144, 88.64524223315198, 214.299486465396, 484.41637206408785, 312.9899934267946, 198.2003632592305, 219.088092914051, 174.3262419142438, 168.28683719970633, 149.7179267482208, 111.62829194124694, 108.26076228130526, 108.1912211146981, 105.14149187014388, 97.09177258271018, 89.5273611635911, 85.30105723168658, 83.5683277599588, 78.90363663660696, 73.55384451774978, 85.06207991161996, 70.99875796917674, 62.803247362867374, 61.14628518220258, 60.98292598135417, 59.19159199220525, 57.75969754510494, 56.46156691251724, 55.351148038718314, 52.24006244741963, 51.85590699325548, 51.12452704545518, 50.600954296280406, 477.0948292273414, 185.65536074863425, 179.44924300288665, 72.1554790000831, 344.01125605130534, 433.2662198920047, 321.77134014224174, 316.42653931725323, 219.60277746220973, 190.8235201678822, 137.1894743080124, 137.0154299833807, 135.43515431045464, 133.95988698905367, 132.48708570118555, 129.2642271660179, 109.51717436990083, 105.46502564427738, 100.12708825306757, 96.61177863973782, 94.09234761405519, 88.97634228433108, 83.51884117817008, 80.99079332816324, 75.39000708435856, 72.48524178091733, 66.39139326934496, 66.23655860897888, 64.31222065627782, 59.74106160887561, 59.22697034611269, 58.98500029569314, 55.421014987129354, 55.30830703338574, 51.015610418005664, 49.54185562021374, 144.49276417122522, 109.50731782139736, 252.92997301193304, 252.10649276853002, 195.74335158425592, 191.1424356966506, 165.74995855349843, 162.770233997385, 157.00465954775473, 134.3967694237037, 127.38993074929064, 121.28758031689776, 99.10115577462557, 98.01441372862438, 97.52275027308612, 112.16750887381865, 95.84177365548801, 86.53830372213372, 83.23168624825406, 78.71479756617151, 77.81654855176774, 75.17163427965674, 74.5387071957663, 71.79347199697511, 71.6032044271722, 70.96068481669117, 68.65039141438693, 67.39400410467884, 64.6628643550364, 61.695250997271415, 60.21101442995508, 59.76514004135156, 542.1747897161201, 605.8592024168141, 451.5811881036755, 249.22382179127047, 179.84456615043104, 153.71273120914668, 149.12642571872752, 146.3994670100507, 127.86158959500457, 124.49407662830953, 98.62181968454763, 90.6345665356257, 86.69955720344493, 84.93129396475557, 84.7646748741975, 81.31111280180268, 73.3821479348591, 73.4432509810871, 71.7786586364151, 66.07420503046306, 62.95514476414595, 62.57780868013212, 61.763046750475056, 60.83248644567733, 57.175198853572134, 55.95381296566397, 55.38768581208688, 54.51178232774725, 53.72842101231951, 51.73514408389189, 48.83489958091837, 48.06756589775993, 400.71628472458184, 88.68931957203733, 97.84522594584575, 82.82747062293708, 605.8592024168141, 323.2993352833724, 234.14873128226748, 191.1024883297846, 175.54122079867756, 173.53257628816144, 158.33242593135472, 157.3593825976455, 253.3073942049114, 126.13542745549402, 123.69125092798707, 119.25227373781634, 116.19046269614226, 102.12542305804884, 97.77801986427515, 92.73003511598299, 90.54590111964367, 89.21683542699319, 82.04046554900506, 78.36461184913817, 75.75864505387182, 74.04585028364083, 73.24564298138051, 71.13438702235798, 65.43603399311274, 63.736939851214345, 62.16640467352832, 61.173412422605324, 60.4560262817512, 57.99786347595219, 57.86305940967349, 59.6478841442737, 342.26396465538596, 168.25318430633484, 110.37265889278795, 302.0778347454148, 255.40990893003413, 188.1706074084544, 182.52710236850527, 131.33098295730952, 124.16677982002746, 100.35836018907675, 99.76437920670557, 93.56877069324571, 92.63726669757682, 85.33561647998377, 84.94927986276208, 84.15563874392728, 83.50209646814885, 76.12497254002153, 76.0621456283442, 73.01019762659543, 67.71332883716369, 67.92768429287352, 66.24870577995165, 63.674972940149175, 61.40770542031279, 57.94852323085057, 57.9999136033888, 57.17938437221235, 56.19121863400075, 55.28929347251341, 53.7292057316507, 53.06087630363309, 52.26722927797659, 59.83976847969049, 308.7851045546544, 528.2976135843995, 146.22874002488206, 605.8592024168141, 630.3630296641537, 132.36036509492226, 131.38286083192224, 126.72701959429395, 115.64361820177339, 113.77166408020112, 110.79184209009183, 101.44596948566752, 100.18005879726084, 97.22690120552411, 87.26602775472355, 82.97539110839095, 82.36182278693717, 81.45635220098765, 80.35930198450852, 79.77243278340309, 75.20287898978938, 74.8544387259969, 133.22958281987044, 72.31456345484943, 69.2364042783338, 67.5901007799909, 66.17346068499737, 63.21906856214652, 62.29750272433066, 60.85322086318383, 55.97807932147797, 48.08003325502937, 47.69843098933655, 45.4385537878971, 259.8963063741879, 272.688767197776, 114.7753580203907, 605.8592024168141, 633.2858499036568, 237.96739015325963, 179.68668584134568, 168.55787827379777, 143.6529851387953, 139.87506617915582, 139.3179800414004, 130.29085971882526, 120.20112705070245, 103.8222850914096, 100.28705693725121, 86.6093332519926, 77.83576366943515, 70.98113572466245, 70.2755447511211, 69.46947514802511, 65.07374315688033, 64.95000786401718, 63.931521278022046, 60.840258911614505, 57.72043360597018, 56.20146167411904, 54.581141773308126, 52.66100575039298, 52.32475741976713, 52.32399285308757, 52.27324618172498, 51.86778623088032, 50.471508616844275, 48.79224503389608, 205.14909712602088, 79.91084103253606, 342.1563377214858, 206.3141428235676, 145.2356043056151, 154.50371062521103, 116.07661754966362, 113.15017027500764, 97.14731190531482, 95.20214955876877, 89.94660083529249, 89.84518821030457, 87.29355949021219, 87.96532315150769, 83.79085216374298, 77.96346579556486, 75.17525668803829, 75.11496609557159, 73.93287754284643, 66.64985164570056, 66.31557338880023, 65.92811294513369, 64.94694219490265, 64.21707100061012, 63.40216794809086, 62.466881816473986, 64.01117874378691, 59.83468705352476, 59.600447526738904, 59.53143678409971, 58.84958526855065, 58.642596442300196, 315.6934206642845, 433.2662198920047, 288.640200671036, 185.16536625970474, 169.86551119263999, 158.87213253523075, 154.353831346552, 150.2390488272081, 147.68956973851516, 131.01761811822908, 117.96066224565554, 112.71025846572199, 110.76722602212641, 109.2452646707088, 97.36546788036495, 88.49369196289338, 83.67682960341808, 81.4737373390503, 80.5904667193799, 79.76250896142804, 77.84975062800102, 74.34582328946492, 74.19585642301936, 73.45207470057059, 70.55842707746228, 68.33161055868017, 65.41297802422937, 62.29312776714676, 62.09796727448496, 78.91780370983852, 59.88635461718994, 59.55931645134331, 433.2662198920047, 324.9162208991974, 322.072810568824, 264.08432689335825, 262.40649172477606, 252.98674740079096, 173.69954108768542, 145.94501310157264, 130.86745776231308, 99.95767616605008, 91.61138838582059, 83.63392895762259, 82.02536755825206, 77.6149159078874, 80.91641916266187, 70.95976353087457, 70.75938956204743, 69.84016980615394, 64.34472330740743, 64.13037525837134, 64.09269652191054, 63.26045505405916, 59.10341333691511, 57.63427529941613, 52.49980117755636, 52.24406141100197, 49.82117943860368, 49.63603621200852, 49.06418895276255, 48.103792074608904, 47.23043794880848, 70.0726200142958, 106.24291326666665, 81.70676603759222, 92.18472000677116, 259.8963063741879, 274.6995428288168, 492.59194404708563, 397.6791615591439, 197.21184500772944, 193.66735161875948, 124.15919302544917, 90.41349709926655, 83.3362330050361, 75.5006454029069, 69.6815013876907, 68.19804015253186, 67.32398190036496, 66.09497583942088, 62.99715528275963, 62.91331422245433, 60.30537997454688, 59.64350555778027, 58.409899049849955, 58.121968415327665, 55.7441314038266, 55.010768569439136, 55.06272500181262, 53.65060677185367, 53.375225040607326, 52.01947589461213, 50.637678469592096, 49.25866727203982, 48.59207112788193, 48.28762915441747, 47.44451138699538, 47.13761703449171, 274.6995428288168, 182.02321287167982, 115.1839335159908, 105.97405659994102, 483.2617729228556, 342.26396465538596, 311.65879328069184, 283.9410325419924, 268.76110420999726, 262.6868530905669, 207.55298998736768, 150.9380034891649, 133.63357652743986, 120.63649301260105, 101.3323617220693, 100.8154606276914, 98.56288132493589, 93.01728785469798, 112.14030436999136, 85.594616114664, 83.96966730949363, 77.67267018155665, 76.24433406504447, 71.1225149849115, 68.61811456827513, 63.89468797592341, 60.23175271068887, 59.99692429272362, 58.59998145040442, 58.587679594064724, 58.43177873947917, 55.989716176195465, 53.18610705433437, 52.683128805550616, 52.54916956060162, 51.75744739449865, 94.85137728907753, 372.93743003732413, 184.96872496823315, 164.6034498967392, 153.77475456748235, 137.11594740829906, 136.09289471444595, 125.5972798563126, 108.34619459616026, 106.84177124873953, 104.86467199561187, 96.92857020927886, 91.40032982402028, 87.56052912207912, 86.34085223353416, 83.90727139964969, 81.47895856642496, 80.078754353249, 74.94729998788296, 71.941965755055, 68.3046834234116, 67.16820977960205, 66.21322692229501, 65.0406331036659, 62.56343758566989, 60.47361498071383, 54.74986886522199, 54.58110494397718, 53.59110399955774, 53.53905385917548, 52.74868456658644, 79.53992689843831, 477.0948292273414, 344.01125605130534, 253.32915122869838, 219.566261882733, 206.36816504387656, 195.83580190581927, 163.64340231450365, 163.5736383051723, 146.4824344504693, 138.87771025124624, 120.1554763502859, 101.85430301294245, 100.10304039493482, 83.60678763722748, 83.10827126314572, 78.61542671769186, 75.54639699671027, 73.5395045202484, 72.50167423685063, 71.87412753715378, 69.55102906677888, 68.00930812404235, 66.0815093183542, 64.6426176638301, 64.55093306182133, 61.898340308647974, 61.61496000124463, 52.253239389944106, 50.912657394889024, 49.13650414773949, 48.402624189956164, 46.742178565258705, 70.74180611489125, 163.36243323309932, 164.59094722693382, 154.01649656919656, 143.19333264110816, 136.1252180686041, 120.77657200903842, 120.75533929158901, 116.60660738902087, 107.75156386234383, 107.26898790533443, 103.82647996264849, 88.27048356375703, 81.91543055216863, 77.98178992268448, 77.9145075179511, 76.64050933677805, 69.58501924871003, 68.95053079114717, 65.96565344387089, 64.92559465879106, 62.597291466650184, 67.1597572212344, 56.80517268564711, 55.384788724979764, 54.52588942095225, 51.997936314074146, 50.162679493274894, 49.75814605355745, 48.07102796023842, 47.914851996812715, 229.5891320773506, 308.7851045546544], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.2751, -3.1459, -3.3096, -3.4841, -3.4809, -3.6619, -3.7834, -3.8097, -3.9234, -3.9957, -4.0022, -4.021, -4.0692, -4.2616, -4.2889, -4.3275, -4.3418, -4.3637, -4.3745, -4.3946, -4.4424, -4.4526, -4.5101, -4.5362, -4.553, -4.5674, -4.5682, -4.6583, -4.6657, -4.6751, -3.7103, -3.7855, -3.8228, -4.2432, -4.2688, -3.8319, -4.4575, -2.5015, -3.1786, -3.5801, -3.5997, -3.5745, -3.7245, -3.7469, -3.7664, -3.8709, -3.8934, -3.9765, -4.0604, -4.1321, -4.1449, -4.1817, -4.2176, -4.2331, -4.2346, -4.2756, -4.4609, -4.4859, -4.4881, -4.4986, -4.4985, -4.5205, -4.5258, -4.5789, -4.5889, -4.6067, -4.6242, -2.6076, -4.2117, -4.3582, -4.1654, -4.3418, -4.501, -3.101, -3.2005, -3.5263, -3.5524, -3.6951, -3.7521, -3.9604, -4.0814, -2.8817, -4.1178, -4.205, -4.215, -4.3242, -4.3081, -4.3279, -4.3905, -4.4313, -4.4352, -4.4673, -4.4933, -4.6238, -4.6297, -4.6698, -4.6909, -4.7204, -4.7468, -4.7613, -4.7652, -4.7731, -4.7819, -2.7213, -3.3447, -3.9891, -4.0073, -3.614, -4.0656, -4.2049, -4.1984, -4.2175, -3.5399, -4.446, -4.4439, -2.4513, -2.7738, -2.8803, -2.9943, -3.0657, -3.2383, -3.2657, -3.5129, -3.5849, -3.597, -3.6605, -3.7465, -3.8599, -3.9544, -3.9726, -4.0759, -4.1804, -4.2344, -4.2916, -4.3763, -4.3903, -4.4847, -4.5201, -4.5488, -4.5621, -4.6219, -4.6798, -4.6875, -4.7142, -4.7392, -3.9832, -3.7022, -4.4531, -4.4566, -4.4661, -2.3346, -2.7725, -3.2311, -3.131, -3.3601, -3.3956, -3.5132, -3.8089, -3.8398, -3.8404, -3.8693, -3.9497, -4.0316, -4.0805, -4.1013, -4.1594, -4.2305, -4.0855, -4.2663, -4.3907, -4.4179, -4.4206, -4.4509, -4.4757, -4.4989, -4.5191, -4.5779, -4.5855, -4.5999, -4.6104, -2.5264, -3.597, -3.6351, -4.4555, -4.1892, -4.2151, -2.7035, -2.7205, -3.0875, -3.228, -3.5599, -3.5612, -3.5729, -3.5839, -3.595, -3.6198, -3.7869, -3.8249, -3.8774, -3.9135, -3.9402, -3.9966, -4.0606, -4.0917, -4.1643, -4.2041, -4.2931, -4.2954, -4.3254, -4.4002, -4.409, -4.4132, -4.4765, -4.4786, -4.5609, -4.5907, -3.5217, -4.2981, -2.9445, -2.9477, -3.2019, -3.2258, -3.3691, -3.3873, -3.4237, -3.5801, -3.634, -3.6835, -3.8873, -3.8984, -3.9035, -3.7637, -3.921, -4.0242, -4.0636, -4.12, -4.1317, -4.1667, -4.1752, -4.2132, -4.2159, -4.2251, -4.2586, -4.2773, -4.3193, -4.367, -4.3917, -4.3993, -3.8531, -3.8776, -2.3302, -2.9263, -3.254, -3.4119, -3.4424, -3.461, -3.5973, -3.6242, -3.8592, -3.9445, -3.9893, -4.0102, -4.0121, -4.0543, -4.1581, -4.1573, -4.1805, -4.2644, -4.3135, -4.3196, -4.3329, -4.3483, -4.4114, -4.4333, -4.4436, -4.4599, -4.4746, -4.5131, -4.5719, -4.588, -2.7132, -4.2009, -4.1667, -4.2836, -3.8395, -2.6512, -2.9749, -3.179, -3.2643, -3.2759, -3.3681, -3.3743, -2.8988, -3.597, -3.6167, -3.6535, -3.6797, -3.8099, -3.8538, -3.9073, -3.9314, -3.9464, -4.0312, -4.0775, -4.1118, -4.1349, -4.146, -4.1756, -4.2603, -4.2869, -4.3123, -4.3286, -4.3406, -4.3828, -4.3852, -4.3555, -3.0624, -3.6807, -4.0201, -2.704, -2.8724, -3.1792, -3.2098, -3.541, -3.5975, -3.8122, -3.8182, -3.883, -3.8931, -3.976, -3.9806, -3.9901, -3.998, -4.0916, -4.0924, -4.1339, -4.2103, -4.2072, -4.2324, -4.2726, -4.3094, -4.3684, -4.3675, -4.3819, -4.3997, -4.4161, -4.4453, -4.458, -4.4733, -4.3415, -2.8834, -2.4491, -4.0834, -4.1827, -1.9481, -3.5145, -3.5222, -3.5584, -3.6505, -3.667, -3.6938, -3.7827, -3.7954, -3.8256, -3.9349, -3.9858, -3.9933, -4.0044, -4.0182, -4.0256, -4.0853, -4.09, -3.5138, -4.125, -4.169, -4.1934, -4.2149, -4.2613, -4.2762, -4.3001, -4.3849, -4.5398, -4.5479, -4.5974, -3.1072, -3.124, -3.9732, -3.0557, -1.9276, -2.9088, -3.1909, -3.2552, -3.4161, -3.4429, -3.4469, -3.5144, -3.5956, -3.7433, -3.7783, -3.9264, -4.0345, -4.1278, -4.1379, -4.1496, -4.2159, -4.2179, -4.2339, -4.2842, -4.3377, -4.3648, -4.3946, -4.431, -4.4376, -4.4376, -4.4386, -4.4465, -4.4743, -4.5088, -3.3457, -4.3223, -2.5333, -3.041, -3.3939, -3.3324, -3.6197, -3.6454, -3.7995, -3.8197, -3.8771, -3.8782, -3.9074, -3.8997, -3.9488, -4.0217, -4.0586, -4.0594, -4.0755, -4.1806, -4.1857, -4.1916, -4.2068, -4.2183, -4.2312, -4.2464, -4.222, -4.2901, -4.294, -4.2952, -4.3069, -4.3105, -2.9385, -3.1748, -2.6894, -3.1351, -3.2218, -3.2891, -3.3181, -3.3453, -3.3626, -3.4831, -3.5889, -3.635, -3.6524, -3.6663, -3.7825, -3.8792, -3.9356, -3.9626, -3.9736, -3.9841, -4.0086, -4.0553, -4.0573, -4.0675, -4.1082, -4.1408, -4.185, -4.2346, -4.2378, -3.9987, -4.2747, -4.2802, -4.1713, -2.5673, -2.5761, -2.7753, -2.7817, -2.8184, -3.1961, -3.3712, -3.481, -3.7527, -3.8409, -3.9328, -3.9525, -4.0084, -3.9668, -4.0992, -4.1021, -4.1153, -4.1984, -4.2018, -4.2024, -4.2157, -4.2847, -4.3103, -4.4052, -4.4102, -4.4586, -4.4624, -4.4742, -4.4943, -4.513, -4.1258, -3.8719, -4.1777, -4.1853, -4.2288, -4.2866, -2.1494, -2.3639, -3.0677, -3.0859, -3.5332, -3.8532, -3.9356, -4.0356, -4.1168, -4.1387, -4.1517, -4.1704, -4.2191, -4.2205, -4.2635, -4.2747, -4.2959, -4.3009, -4.3434, -4.3569, -4.356, -4.3824, -4.3876, -4.4138, -4.4412, -4.4694, -4.4833, -4.4897, -4.5076, -4.5143, -2.9731, -3.4576, -3.9269, -4.0316, -3.6555, -4.1106, -2.5674, -2.6608, -2.7159, -2.7389, -2.9754, -3.2956, -3.4182, -3.5213, -3.6972, -3.7023, -3.7251, -3.7836, -3.5972, -3.8677, -3.8871, -3.9659, -3.9847, -4.0551, -4.0915, -4.1638, -4.2238, -4.2278, -4.2517, -4.2519, -4.2546, -4.298, -4.3503, -4.36, -4.3626, -4.378, -4.3386, -2.2984, -3.0022, -3.1195, -3.1879, -3.3033, -3.3109, -3.3917, -3.5407, -3.5548, -3.5736, -3.6531, -3.7124, -3.7558, -3.7699, -3.7988, -3.8286, -3.8461, -3.9131, -3.9546, -4.0072, -4.0242, -4.0387, -4.0568, -4.0962, -4.1307, -4.2318, -4.235, -4.2536, -4.2546, -4.2697, -4.1588, -3.8723, -4.2065, -2.6599, -2.8035, -2.8658, -2.9184, -3.0989, -3.0994, -3.2104, -3.2641, -3.4099, -3.5766, -3.5941, -3.776, -3.7821, -3.8383, -3.8786, -3.9059, -3.9203, -3.9291, -3.9627, -3.9851, -4.0143, -4.0366, -4.0381, -4.0807, -4.0853, -4.2529, -4.2794, -4.3156, -4.3309, -4.3666, -4.1966, -2.9782, -2.9709, -3.0375, -3.1108, -3.1618, -3.2823, -3.2824, -3.3177, -3.3973, -3.4019, -3.4348, -3.5987, -3.6742, -3.724, -3.7249, -3.7425, -3.8394, -3.8487, -3.8936, -3.9097, -3.9468, -3.8767, -4.0454, -4.0712, -4.0871, -4.1354, -4.172, -4.1803, -4.2154, -4.2187, -2.8578, -4.0391], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.6626, 2.6607, 2.66, 2.6593, 2.6592, 2.6584, 2.6575, 2.6574, 2.6566, 2.6561, 2.656, 2.6559, 2.6554, 2.6537, 2.6534, 2.653, 2.6528, 2.6526, 2.6524, 2.6522, 2.6516, 2.6515, 2.6505, 2.6504, 2.6502, 2.65, 2.65, 2.6487, 2.6485, 2.6484, 2.4585, 2.3874, 2.2983, 2.4409, 2.213, 1.3265, 1.2157, 2.7328, 2.731, 2.7291, 2.729, 2.729, 2.7282, 2.7281, 2.728, 2.7272, 2.7271, 2.7264, 2.7257, 2.725, 2.7249, 2.7245, 2.7241, 2.724, 2.7239, 2.7235, 2.7212, 2.7209, 2.7208, 2.7207, 2.7207, 2.7204, 2.7203, 2.7195, 2.7194, 2.7191, 2.7188, 2.5248, 2.5135, 2.4485, 1.2694, 1.4779, 0.5204, 2.7806, 2.7802, 2.7786, 2.7784, 2.7776, 2.7772, 2.7756, 2.7745, 2.7741, 2.774, 2.7732, 2.7731, 2.7718, 2.7717, 2.7717, 2.7709, 2.7704, 2.7703, 2.7698, 2.7695, 2.7675, 2.7674, 2.7667, 2.7663, 2.7658, 2.7653, 2.765, 2.7649, 2.7648, 2.7646, 2.5262, 2.5656, 2.6248, 2.6141, 2.4466, 2.5539, 2.5569, 2.525, 2.5289, 2.0474, 2.4469, 2.3474, 2.857, 2.8562, 2.8559, 2.8555, 2.8553, 2.8545, 2.8544, 2.8531, 2.8527, 2.8526, 2.8522, 2.8516, 2.8507, 2.8498, 2.8496, 2.8486, 2.8475, 2.8468, 2.8461, 2.845, 2.8448, 2.8434, 2.8428, 2.8423, 2.8418, 2.8411, 2.84, 2.8399, 2.8394, 2.8389, 2.6567, 2.5786, 2.5616, 2.4867, 1.5945, 2.9105, 2.9093, 2.9076, 2.9075, 2.907, 2.9067, 2.9061, 2.9039, 2.9037, 2.9037, 2.9034, 2.9027, 2.9018, 2.9013, 2.9011, 2.9004, 2.8995, 2.8991, 2.8991, 2.8973, 2.8969, 2.8968, 2.8964, 2.896, 2.8956, 2.8952, 2.8942, 2.8941, 2.8938, 2.8936, 2.7339, 2.6071, 2.603, 2.6937, 1.3981, 1.1416, 2.9507, 2.9504, 2.9487, 2.9487, 2.9468, 2.9467, 2.9466, 2.9466, 2.9465, 2.9463, 2.945, 2.9447, 2.9442, 2.9439, 2.9436, 2.943, 2.9423, 2.942, 2.9411, 2.9406, 2.9394, 2.9393, 2.9389, 2.9378, 2.9376, 2.9376, 2.9365, 2.9365, 2.935, 2.9345, 2.9331, 2.4339, 2.9504, 2.9504, 2.9493, 2.9492, 2.9485, 2.9484, 2.9481, 2.9471, 2.9468, 2.9464, 2.9445, 2.9445, 2.9445, 2.9443, 2.9443, 2.9432, 2.9428, 2.9421, 2.942, 2.9416, 2.9415, 2.941, 2.9409, 2.9408, 2.9404, 2.9401, 2.9395, 2.9388, 2.9384, 2.9383, 1.2793, 1.1438, 2.9851, 2.9834, 2.9819, 2.981, 2.9808, 2.9807, 2.9798, 2.9796, 2.9776, 2.9767, 2.9762, 2.976, 2.976, 2.9754, 2.9742, 2.9742, 2.9739, 2.9728, 2.9721, 2.972, 2.9718, 2.9715, 2.9705, 2.9702, 2.97, 2.9697, 2.9695, 2.9688, 2.9677, 2.9674, 2.7216, 2.742, 2.6779, 2.7277, 1.1818, 2.9982, 2.9971, 2.9962, 2.9958, 2.9957, 2.9952, 2.9952, 2.9946, 2.9937, 2.9935, 2.9933, 2.993, 2.9919, 2.9915, 2.991, 2.9907, 2.9906, 2.9896, 2.9891, 2.9887, 2.9884, 2.9882, 2.9879, 2.9867, 2.9863, 2.9859, 2.9857, 2.9855, 2.9848, 2.9848, 2.9841, 2.53, 2.6219, 2.704, 3.0133, 3.0128, 3.0114, 3.0113, 3.0093, 3.0089, 3.007, 3.007, 3.0064, 3.0063, 3.0054, 3.0053, 3.0052, 3.0051, 3.004, 3.004, 3.0035, 3.0025, 3.0024, 3.0022, 3.0016, 3.001, 3.0001, 3.0001, 2.9999, 2.9996, 2.9993, 2.9988, 2.9986, 2.9983, 2.9948, 2.8119, 2.7093, 2.3594, 0.8387, 3.0336, 3.028, 3.0277, 3.0276, 3.027, 3.0268, 3.0266, 3.0258, 3.0257, 3.0254, 3.0242, 3.0237, 3.0236, 3.0235, 3.0233, 3.0232, 3.0225, 3.0225, 3.0221, 3.022, 3.0214, 3.0211, 3.0208, 3.0201, 3.0199, 3.0195, 3.0182, 3.0154, 3.0152, 3.0142, 2.7606, 2.6957, 2.7118, 1.9656, 3.0495, 3.0471, 3.0459, 3.0455, 3.0446, 3.0444, 3.0443, 3.0439, 3.0432, 3.042, 3.0417, 3.0402, 3.039, 3.0378, 3.0376, 3.0375, 3.0366, 3.0365, 3.0363, 3.0355, 3.0347, 3.0342, 3.0337, 3.0331, 3.033, 3.033, 3.033, 3.0328, 3.0323, 3.0317, 2.7586, 2.7248, 3.0595, 3.0576, 3.0557, 3.0554, 3.0541, 3.0539, 3.0523, 3.0523, 3.0517, 3.0517, 3.0514, 3.0514, 3.0509, 3.0501, 3.0496, 3.0496, 3.0494, 3.048, 3.0479, 3.0478, 3.0476, 3.0475, 3.0473, 3.047, 3.047, 3.0464, 3.0463, 3.0463, 3.0461, 3.046, 2.7348, 2.1819, 3.0735, 3.0716, 3.0712, 3.0708, 3.0706, 3.0705, 3.0703, 3.0695, 3.0687, 3.0682, 3.0682, 3.0681, 3.067, 3.0659, 3.0654, 3.0651, 3.065, 3.0649, 3.0646, 3.064, 3.064, 3.0639, 3.0633, 3.0629, 3.0623, 3.0615, 3.0615, 3.0609, 3.0609, 3.0608, 1.1854, 3.0771, 3.0771, 3.0765, 3.0765, 3.0763, 3.0746, 3.0736, 3.0728, 3.0706, 3.0696, 3.0687, 3.0685, 3.0679, 3.0678, 3.0667, 3.0667, 3.0665, 3.0653, 3.0653, 3.0653, 3.0651, 3.064, 3.0636, 3.062, 3.0619, 3.061, 3.0609, 3.0606, 3.0603, 3.0599, 3.0527, 2.8904, 2.8472, 2.7189, 1.6389, 1.5258, 3.0789, 3.0785, 3.076, 3.076, 3.0732, 3.0704, 3.0695, 3.0683, 3.0672, 3.0669, 3.0668, 3.0665, 3.0658, 3.0658, 3.0651, 3.0649, 3.0646, 3.0645, 3.0638, 3.0636, 3.0636, 3.0631, 3.0631, 3.0626, 3.0621, 3.0616, 3.0613, 3.0612, 3.0608, 3.0607, 2.8393, 2.7663, 2.7546, 2.7332, 1.592, 1.4818, 3.1187, 3.1184, 3.1183, 3.1181, 3.1172, 3.1155, 3.1147, 3.1139, 3.1124, 3.1124, 3.1122, 3.1116, 3.1111, 3.1107, 3.1105, 3.1096, 3.1094, 3.1085, 3.108, 3.1069, 3.106, 3.106, 3.1056, 3.1056, 3.1055, 3.1048, 3.1039, 3.1038, 3.1037, 3.1034, 2.5371, 3.2082, 3.2056, 3.205, 3.2046, 3.2038, 3.2038, 3.2032, 3.202, 3.2019, 3.2017, 3.201, 3.2004, 3.1999, 3.1998, 3.1994, 3.1991, 3.1989, 3.1981, 3.1976, 3.1969, 3.1966, 3.1964, 3.1962, 3.1956, 3.1951, 3.1934, 3.1933, 3.193, 3.193, 3.1927, 2.8929, 1.388, 1.3808, 3.2334, 3.2328, 3.2326, 3.2323, 3.2314, 3.2314, 3.2307, 3.2303, 3.2293, 3.2279, 3.2277, 3.2258, 3.2258, 3.2251, 3.2246, 3.2243, 3.2241, 3.224, 3.2233, 3.2232, 3.2228, 3.2225, 3.2225, 3.2218, 3.2218, 3.219, 3.2185, 3.2178, 3.2175, 3.2168, 2.9724, 3.3538, 3.3537, 3.3535, 3.353, 3.3527, 3.3518, 3.3518, 3.3515, 3.3509, 3.3508, 3.3505, 3.3489, 3.3481, 3.3475, 3.3475, 3.3464, 3.346, 3.3459, 3.3453, 3.3451, 3.3445, 3.3443, 3.343, 3.3425, 3.3423, 3.3414, 3.3407, 3.3406, 3.3399, 3.3398, 3.134, 1.6563]}, \"token.table\": {\"Topic\": [7, 17, 18, 14, 10, 13, 1, 15, 20, 10, 19, 16, 7, 10, 10, 14, 5, 9, 20, 2, 9, 12, 14, 19, 5, 1, 17, 6, 20, 19, 3, 16, 1, 6, 20, 7, 13, 4, 14, 4, 15, 13, 10, 1, 18, 16, 12, 18, 14, 2, 14, 15, 13, 20, 7, 10, 14, 18, 8, 14, 19, 6, 3, 1, 9, 8, 12, 11, 20, 3, 2, 8, 8, 20, 10, 1, 5, 13, 4, 11, 8, 3, 5, 12, 7, 19, 13, 20, 4, 6, 8, 1, 2, 1, 6, 19, 19, 1, 17, 8, 18, 11, 20, 5, 8, 10, 3, 11, 19, 6, 19, 12, 18, 1, 14, 12, 16, 14, 13, 17, 13, 1, 8, 4, 1, 7, 8, 9, 12, 13, 2, 18, 11, 6, 12, 16, 17, 1, 2, 15, 12, 13, 7, 8, 3, 8, 6, 16, 5, 18, 18, 15, 10, 11, 15, 13, 10, 7, 6, 1, 11, 6, 3, 2, 11, 7, 18, 8, 6, 15, 9, 10, 7, 8, 1, 18, 7, 5, 12, 18, 18, 2, 5, 20, 9, 17, 9, 10, 3, 8, 5, 3, 16, 3, 5, 16, 3, 16, 11, 13, 16, 11, 9, 4, 12, 13, 1, 5, 13, 13, 11, 6, 10, 3, 11, 19, 11, 2, 2, 3, 8, 17, 9, 18, 3, 19, 10, 20, 16, 2, 14, 9, 15, 15, 15, 14, 19, 10, 5, 13, 4, 17, 16, 11, 17, 11, 16, 10, 4, 2, 1, 2, 15, 10, 4, 18, 8, 4, 5, 8, 5, 5, 20, 14, 15, 9, 12, 10, 19, 13, 5, 6, 20, 20, 14, 8, 11, 16, 15, 19, 17, 14, 3, 1, 1, 3, 5, 15, 15, 16, 9, 15, 9, 13, 16, 13, 7, 9, 17, 4, 1, 4, 3, 5, 2, 7, 13, 8, 3, 19, 13, 8, 6, 10, 16, 4, 13, 19, 18, 18, 6, 2, 6, 1, 9, 18, 5, 16, 18, 19, 2, 10, 16, 10, 17, 12, 16, 5, 14, 5, 3, 10, 10, 3, 2, 18, 6, 12, 1, 9, 2, 16, 7, 20, 5, 8, 2, 10, 16, 14, 2, 7, 3, 10, 2, 4, 5, 18, 7, 9, 2, 4, 15, 8, 14, 8, 6, 11, 15, 7, 8, 11, 18, 9, 4, 1, 18, 2, 10, 12, 8, 20, 15, 15, 3, 1, 18, 4, 8, 10, 19, 14, 19, 17, 20, 18, 17, 12, 2, 3, 5, 15, 18, 12, 1, 13, 6, 3, 2, 20, 19, 5, 18, 19, 4, 2, 14, 16, 2, 18, 4, 6, 1, 3, 4, 9, 3, 4, 20, 7, 12, 11, 9, 2, 14, 12, 17, 12, 5, 7, 16, 2, 3, 17, 1, 3, 1, 10, 16, 3, 9, 14, 20, 3, 11, 13, 7, 7, 5, 7, 1, 7, 16, 9, 9, 12, 14, 17, 14, 15, 18, 15, 4, 2, 3, 8, 5, 1, 7, 13, 14, 18, 11, 5, 20, 9, 8, 15, 19, 8, 16, 15, 1, 5, 20, 3, 8, 13, 9, 10, 2, 2, 9, 11, 8, 4, 5, 2, 14, 17, 11, 7, 5, 18, 11, 17, 6, 9, 19, 20, 2, 10, 5, 6, 7, 14, 4, 11, 17, 14, 4, 4, 12, 3, 14, 8, 11, 1, 3, 11, 2, 4, 5, 10, 13, 14, 18, 12, 15, 19, 12, 14, 20, 19, 20, 7, 7, 3, 9, 18, 12, 19, 3, 17, 2, 6, 17, 2, 13, 7, 4, 7, 10, 20, 6, 20, 19, 14, 15, 6, 5, 14, 2, 19, 15, 4, 16, 4, 13, 16, 13, 1, 15, 15, 11, 17, 19, 20, 18, 16, 2, 20, 6, 14, 8, 11, 9, 2, 4, 11, 20, 6, 18, 1, 20, 4, 4, 15, 3, 4, 12, 11, 11, 2, 12, 12, 6, 3, 12, 9, 17, 1, 6, 8, 4, 8, 10, 16, 4, 15, 16, 17, 14, 1, 9, 19, 13, 16, 9, 10, 19, 5, 5, 15, 1, 3, 3, 1, 16, 17, 7, 2, 4, 1, 4, 6, 8, 1, 2, 7, 8, 10, 11, 12, 9, 3, 4, 3, 10, 1, 4, 19, 12, 10, 7, 7, 16, 2, 3, 15, 1, 12, 17, 19, 15, 10, 17, 9, 6, 12, 8, 13, 15, 14, 11, 16, 20, 1, 20, 4, 6, 17, 10, 11, 6, 6, 3, 3, 7, 17, 1, 14, 5, 17, 16, 17, 16, 11, 17, 6, 6, 10, 11, 17, 8, 13, 7, 10, 20, 15, 17, 1], \"Freq\": [0.9793156064371301, 0.9859974591900262, 0.9917544013712449, 0.9906090854518077, 0.9757548028567385, 0.9898350106569687, 0.9855584685340931, 0.9813308018163829, 0.994797830049226, 0.9894654590253701, 0.9974209977531274, 0.980334171227062, 0.9897489175333017, 0.9888253336073517, 0.9864281311863663, 0.9912290395726401, 0.988123656863037, 0.9780543852449265, 0.9904581899207507, 0.9911547928198783, 0.9829936235019855, 0.9818493793874041, 0.9936983689382808, 0.9933702708284213, 0.9868472727975819, 0.9916037037050139, 0.9868515674615022, 0.9937877349487736, 0.9874100104183569, 0.9851592649317727, 0.9824176941724205, 0.9878154786544547, 0.9800578425835473, 0.9795960916465458, 0.9916662834847272, 0.9956110104250828, 0.9905615930221415, 0.989975423955708, 0.9944211620970634, 0.9943089404350899, 0.9783102711880733, 0.9859223493033074, 0.9906031241067971, 0.9836210901912009, 0.9918612865287213, 0.9866509462953885, 0.9920798787015175, 0.9919694946842075, 0.9937063486371946, 0.99282873653983, 0.014270909233820371, 0.9704218278997853, 0.987642086126709, 0.9809067134993222, 0.9940231184535929, 0.9863430602333834, 0.9838824365581641, 0.986906588593059, 0.9837424448774252, 0.9890847353890511, 0.9900193069794704, 0.9792835875456322, 0.988657221328821, 0.9792071348613348, 0.9825863764658821, 0.9904407643099232, 0.9746962572828682, 0.9912694200307274, 0.9916600579084465, 0.978174744254628, 0.23208440371700956, 0.7661280853884079, 0.9929986255809337, 0.9808081553843506, 0.9766809559041595, 0.993814347345315, 0.9875140613452732, 0.9801619239407434, 0.9852447542132546, 0.984004881116949, 0.9848281698386322, 0.26191250079134604, 0.7355840447756953, 0.9871662707376435, 0.9890891631613641, 0.9866647296797137, 0.990724940367917, 0.993744878727349, 0.7390641694481366, 0.24231612113053658, 0.9890347371236092, 0.9934977298270338, 0.9882970302327639, 0.9924563242707366, 0.993305647204931, 0.9768704720156253, 0.9889809501231629, 0.9953049009776787, 0.9836796519990204, 0.26401834674570607, 0.7291935291071883, 0.9885853298676842, 0.9916426790176526, 0.9872100982577169, 0.9932615447865648, 0.9793739581990761, 0.9900066048364875, 0.9854923182904355, 0.9903834899133739, 0.9963235231675023, 0.9854868433601205, 0.996178426697947, 0.9816769703171423, 0.9899032754282431, 0.982318788799773, 0.9746820150710022, 0.9878732634913089, 0.9805125249091466, 0.9899254527162816, 0.9823232507005233, 0.9910730059140509, 0.9953054076577139, 0.99097884967609, 0.998411102648739, 0.6939918056175056, 0.12392710814598314, 0.17845503573021573, 0.996916844965444, 0.9900073561689999, 0.9966204404419741, 0.9934929258903481, 0.9904200566739613, 0.9903170461718225, 0.9800921637576405, 0.9861890970445213, 0.9854829739341826, 0.9909919622221607, 0.8008268270941866, 0.19150206734860983, 0.9835174628971671, 0.9979695584484441, 0.9894759687803447, 0.9895913809128808, 0.9864425382582435, 0.9928056495095967, 0.9936949076123662, 0.9875954395700676, 0.990630920753518, 0.9847474665155348, 0.9899315766656362, 0.986528831998431, 0.9770539488259694, 0.9811512426506974, 0.7618423007325384, 0.23855668002736055, 0.9914924146078185, 0.9861636092020734, 0.989384071200583, 0.9894033840935799, 0.9927127225113408, 0.9825274583670345, 0.9877665931219036, 0.9931719469327027, 0.2860403851671238, 0.71143377849259, 0.9915757341867888, 0.9873604521038635, 0.9863151007904184, 0.9956843885535824, 0.9904799415169971, 0.9939710013054888, 0.9788006264509104, 0.9896071205454338, 0.9803487595959122, 0.9933810692779531, 0.9935983812832194, 0.9852017145900381, 0.9943715707700909, 0.9861775144248424, 0.992168237654308, 0.9863037322140817, 0.981126395435513, 0.9891432787395323, 0.9777198864745661, 0.9808182611344448, 0.9913396799674284, 0.9920429983614404, 0.9770760784712998, 0.9922034122089483, 0.9907665561910995, 0.995204804369031, 0.7718384132558795, 0.2255506355090908, 0.2585435713057001, 0.7379264431016858, 0.9744478009303701, 0.9916763359557831, 0.9804020344865159, 0.9821422806221509, 0.9778845425405822, 0.9834332969259093, 0.9932174317178208, 0.984052902262285, 0.9981138395219243, 0.9874479087329613, 0.9902497660586693, 0.8162918269430193, 0.18197588498729728, 0.9936303793545971, 0.9855634451003571, 0.9791724761412641, 0.9827481729931384, 0.01384152356328364, 0.7996804910480104, 0.018816011554070835, 0.17875210976367292, 0.9928528845161005, 0.9932139440551091, 0.9957958775672948, 0.0102202227071709, 0.7358560349163047, 0.25550556767927246, 0.9959810146772077, 0.9844702455576019, 0.985673857199034, 0.9927423639350867, 0.9836316237590401, 0.976821822418183, 0.9733341815084811, 0.9904482348925896, 0.9851993893624723, 0.9863609214430282, 0.9761875057680721, 0.9886744968185055, 0.9871859991137922, 0.9792412451662325, 0.9914651417773669, 0.9893997137496452, 0.9923921843339213, 0.9890260944094407, 0.9781974307911793, 0.9890634539217368, 0.9933689917452332, 0.9822668986501502, 0.9973852780126378, 0.9873810520513184, 0.9783538388266877, 0.9862678394320823, 0.9954335064113697, 0.994604600965564, 0.15059827999859587, 0.018824784999824484, 0.8282905399922773, 0.985966381538132, 0.9837528793043494, 0.9909941395899425, 0.9891519477905084, 0.8162228621139147, 0.17490489902441028, 0.9777903066689366, 0.9762622326750131, 0.988354393089998, 0.9862143078488206, 0.9818977956000976, 0.9889948247614635, 0.9897542133104718, 0.9959347784894536, 0.9852220302683184, 0.9841218662022242, 0.9851815013871988, 0.9970761267666228, 0.9883906859404152, 0.9749969484968859, 0.993025030585134, 0.9922329673455764, 0.9919312482553587, 0.2691347573721844, 0.7205866084481065, 0.9920773487841285, 0.9947532637982968, 0.9971681013432563, 0.9917528176803545, 0.9897606960910488, 0.9880230312261099, 0.3487914811295075, 0.6491397009910278, 0.992470216596005, 0.9958940126961942, 0.21113977621776964, 0.7863136493627283, 0.9812373792620985, 0.9971801318608785, 0.6252484108733719, 0.17238157122209785, 0.20159878668347037, 0.9873726637020241, 0.9864617313210428, 0.9889799912269726, 0.9897614054551841, 0.9913510080794844, 0.2384307832988285, 0.7560000446060415, 0.9855637337206725, 0.9885475920359833, 0.9936777671531815, 0.9954753620450748, 0.9860501141624073, 0.9857902380111322, 0.989190872765624, 0.9957321291730854, 0.9902674788901434, 0.995363225911477, 0.9954917203837225, 0.9923381550330522, 0.9816259871344415, 0.9942467319032424, 0.9873821015243753, 0.9900589164385021, 0.9947627634433901, 0.988970109674124, 0.9955907122627945, 0.9890924572464427, 0.9936676599028456, 0.9800113069164341, 0.74293761537132, 0.2446258001832395, 0.9931992445560085, 0.9874070358502903, 0.9893533678995023, 0.971021732531452, 0.9925334069239101, 0.9800064307727905, 0.9758660469904685, 0.9860358182171974, 0.9754965744605718, 0.9786222343987129, 0.9843663043172122, 0.9939436878949585, 0.9904402585706428, 0.992353310448284, 0.9950798217120506, 0.9964319303787278, 0.9864649025101887, 0.9965685375658951, 0.9849683320211206, 0.98757506342352, 0.9833008342670965, 0.9937439444851807, 0.9833725645444845, 0.988437790503676, 0.26370263024550816, 0.7306760379719288, 0.9896503617168694, 0.9935701767642461, 0.9968369805821726, 0.9950894670402116, 0.9949809969833971, 0.9939213619134705, 0.9987983074952013, 0.9977820114123132, 0.8097019786365539, 0.18813121143719475, 0.9812168298168885, 0.9939870196152456, 0.9835298871124425, 0.9862962985746524, 0.8363117257971198, 0.1613934909433038, 0.9909191462307883, 0.98731765425705, 0.28204240353596827, 0.010847784751383396, 0.6942582240885373, 0.7726905037502948, 0.2173192041797704, 0.9987129931029322, 0.007505840511052441, 0.9907709474589224, 0.9959726946697443, 0.9962024172047756, 0.27009281900469106, 0.7231517412061083, 0.9808990634606408, 0.9915846301001389, 0.9952151379965066, 0.9828069343164537, 0.9941216901289368, 0.7981273948433244, 0.19046221922397513, 0.9854293897689201, 0.9811650657039089, 0.9853612691839314, 0.9864745387650993, 0.9946400269462417, 0.9836383546920306, 0.9988662535791976, 0.9963339170769643, 0.9885115517041982, 0.9829036285917828, 0.9971121967002955, 0.9878380779411629, 0.9953309516729174, 0.9916124995442372, 0.99788617136787, 0.982731366681181, 0.9921213282136647, 0.989831449304533, 0.9892624722873588, 0.11627526511526257, 0.4796354686004581, 0.22092300371899887, 0.023255053023052513, 0.15987848953348602, 0.9906579250399716, 0.9935895682785718, 0.9881899778510284, 0.9972551464549967, 0.9737368416996667, 0.9899358811474142, 0.9964096006682613, 0.9964930883049622, 0.9889896693795956, 0.22617460422221222, 0.7633392892499662, 0.9943000263085642, 0.992176181064427, 0.9920856076220461, 0.9806963107768425, 0.9944284355801473, 0.9840002617747083, 0.9831053928342173, 0.9790425655973181, 0.27887311295768547, 0.7186345603140356, 0.003947772638611001, 0.9948387049299723, 0.7139541140463986, 0.28464837226686485, 0.9934000799145573, 0.9888885677869409, 0.9875185690584337, 0.9683406783892785, 0.9950940102217224, 0.9987054963587554, 0.9883701311149882, 0.9832692641436918, 0.9899692290574303, 0.9954544269430643, 0.981253396199182, 0.9912170484395056, 0.989210802554909, 0.9872806425360274, 0.9761763491150685, 0.9930531131319352, 0.14717145094006975, 0.8421477470459546, 0.2631092710355272, 0.7363273844087777, 0.993855110438818, 0.9826835694795152, 0.9899860266332331, 0.9938453106680311, 0.9882626798643321, 0.9820985374998481, 0.9853573592495591, 0.9842030913407439, 0.9927727858983191, 0.9889478531278089, 0.9798688977251674, 0.9871975529410262, 0.75705217234125, 0.2349472258990086, 0.9841714236415288, 0.9894989529460081, 0.9924568928889583, 0.17922776121836673, 0.2530274276024001, 0.5587689026219669, 0.99451047505114, 0.9829513098807289, 0.9826076981441775, 0.9935248688427953, 0.9709796972885123, 0.2172890004591553, 0.7695652099595084, 0.9924465049484114, 0.9918251132981767, 0.23440463169707065, 0.03484393173875375, 0.7222196760396231, 0.006335260316137045, 0.9891872136405394, 0.9830846964702287, 0.975589520965795, 0.9847633781865303, 0.996930972273027, 0.9960313242068163, 0.990419183370578, 0.9921716799947947, 0.7779967230885697, 0.20295566689267036, 0.9933714784626703, 0.9965167615000322, 0.8038197625981139, 0.18016649851337038, 0.9934584498627076, 0.983875355328139, 0.9810475473009574, 0.98587563949047, 0.9931208387261982, 0.9814506652963849, 0.9934024975108885, 0.9909983461554078, 0.9859790352740387, 0.9829535662520572, 0.9759787325630677, 0.9950335369687212, 0.7478040299230699, 0.03935810683805631, 0.19679053419028156, 0.9944344684835923, 0.9887308830739312, 0.9780041574867704, 0.9846791600564634, 0.9897222624465665, 0.9884521715928724, 0.9815624492142149, 0.9891381873210017, 0.9836337073788083, 0.9917339484588592, 0.9910870813942643, 0.9827600846058782, 0.9838819478479156, 0.9952776870579765, 0.9895067493102122, 0.9886012023087469, 0.9931509264923759, 0.9956038718154246, 0.9895494150489229, 0.9949047267655267, 0.9833704602736901, 0.98940831824578, 0.9853732448192128, 0.9948437597915744, 0.9926732435805845, 0.9794456534102861, 0.9978377068450859, 0.21306295487143823, 0.7781429656174265, 0.9882448145725906, 0.13848298631487013, 0.0023080497719145023, 0.17079568312167318, 0.12232663791146861, 0.41544895894461037, 0.15002323517444263, 0.997486361084136, 0.9932419937386203, 0.9933262840287309, 0.9960682660870916, 0.7457990414942638, 0.24859968049808795, 0.9903552344301574, 0.996706537188031, 0.99203979598513, 0.9798871611544782, 0.9963231996553877, 0.9806174649618619, 0.9921273068098174, 0.995244484140135, 0.9756424887542164, 0.9760160440850049, 0.8520447847706892, 0.13795010801049254, 0.9934497516403439, 0.9976028314333378, 0.9870332529400068, 0.9757702103827063, 0.9854197570678398, 0.9946397094870448, 0.2530282350357675, 0.21883523030120433, 0.5197336719653602, 0.006838600946912635, 0.9887434232560633, 0.9888246872903191, 0.9930805151449089, 0.9941853982090099, 0.9874993847784483, 0.9890269451489576, 0.9859327402655362, 0.9859758504725441, 0.9883557576675256, 0.9820740569911669, 0.9879701064804698, 0.9789312205135313, 0.9965541346376585, 0.9816251385301923, 0.9925259304947273, 0.9806997383115775, 0.9905928383351349, 0.996942575334783, 0.9823737931702842, 0.9924201939867754, 0.004355606865847165, 0.004355606865847165, 0.1916467020972753, 0.7970760564500313, 0.9949617570864511, 0.9839657618678858, 0.9810036127113758, 0.9881700393551367, 0.9928345192682038, 0.9783991179287694, 0.9953039106573585, 0.97753676148058, 0.9913612866598408, 0.3045848747187744, 0.6881361984387124, 0.9807167585686883, 0.9857437630928848, 0.9813311766953536, 0.985806573704386, 0.9962372830259713, 0.9856069264326691, 0.9920834149641534, 0.9914843530907068, 0.9800751503766131, 0.8029994723044528, 0.19271987335306867, 0.996690286567967, 0.9834653636738944, 0.9818215945440893, 0.9851691007454382, 0.9893527003205286, 0.9837628903251796, 0.9925889370014467, 0.9767004240958344, 0.9834995943864526, 0.9850844490685675, 0.9795497780613267, 0.6399577685539513, 0.20620861431182874, 0.1493234793292553, 0.9778879415397234, 0.9876455778880567, 0.2830881534831865, 0.7077203837079663, 0.9841280404678521, 0.7955277531128125, 0.19582221615084616, 0.9833837433422479, 0.9919113856652327, 0.9950126752922309, 0.9827948235305956, 0.9926637455097368, 0.9890421556805988, 0.9906636552863906, 0.6834937506479642, 0.3090580437712534, 0.9936799775164902, 0.9887552513084451, 0.9834945131059649, 0.9966690433541121, 0.006225984918494791, 0.9899316020406718, 0.9948855423418894, 0.9812548807308233, 0.9982921872081978, 0.995258852274228, 0.9936010845114495, 0.9835285192062553, 0.9864529526779365, 0.9807864445035627, 0.19176800617334333, 0.5935676381555866, 0.20089981599112158, 0.10563510423659422, 0.1089362012439878, 0.1634043018659817, 0.16505485036967849, 0.11388784675507815, 0.3433140887689312, 0.9905397706670112, 0.9942309054192846, 0.9790202388830614, 0.9975302590658577, 0.7915297521926631, 0.19584241291364862, 0.9898699095613138, 0.9903988847634335, 0.9927673983349058, 0.9900924767738044, 0.9898654306292509, 0.9905260348704926, 0.9952679677452736, 0.9758619844789207, 0.9856664856132457, 0.9901432705318395, 0.973948199461074, 0.9883395549460402, 0.9929645774985968, 0.9853654414460332, 0.9920773412820418, 0.9791012652120205, 0.9843486631364871, 0.9947238766918186, 0.9944114808217962, 0.2627928792721598, 0.7258089046564413, 0.9906115282624552, 0.9851565386563181, 0.9960996083355002, 0.9930735286087858, 0.988220621834042, 0.990219766019406, 0.9858257153780197, 0.9921013049964214, 0.9915927414402365, 0.9977485380627517, 0.9890626700709884, 0.9776989307917826, 0.9937790103110343, 0.9942631050850762, 0.9743596361874758, 0.9913296970193075, 0.9902230655692942, 0.9908766537089071, 0.9844138777760507, 0.9937855048597337, 0.9944275466283093, 0.9918560795830822, 0.9941094972895776, 0.984217164070342, 0.9742347682925726, 0.9942891145493179, 0.982432924027548, 0.994397586085593, 0.9919113534510062, 0.9763451983334799, 0.9902198218816238, 0.9944798189861132, 0.9894745720776218, 0.9966858170037357, 0.9749459506794549, 0.9843664426326423, 0.9937795900892377, 0.816101542085222, 0.18135589824116047, 0.9892680029216259, 0.9973356684121903, 0.9871945628461382], \"Term\": [\"able\", \"absence\", \"account\", \"act\", \"added\", \"adrian\", \"affection\", \"afterward\", \"age\", \"ago\", \"air\", \"alas\", \"alive\", \"altogether\", \"amidst\", \"ancient\", \"animal\", \"answer\", \"apartment\", \"apparent\", \"apparently\", \"appear\", \"appearance\", \"appeared\", \"approached\", \"arm\", \"arms\", \"arose\", \"arrived\", \"art\", \"asked\", \"aspect\", \"atmosphere\", \"attempt\", \"attention\", \"away\", \"beautiful\", \"beauty\", \"bed\", \"began\", \"behold\", \"beings\", \"believe\", \"beloved\", \"beneath\", \"bent\", \"best\", \"better\", \"black\", \"blood\", \"blue\", \"blue\", \"boat\", \"bodies\", \"body\", \"book\", \"books\", \"bore\", \"born\", \"box\", \"brain\", \"breath\", \"brief\", \"bring\", \"broken\", \"brought\", \"building\", \"business\", \"called\", \"calm\", \"came\", \"came\", \"care\", \"carefully\", \"carried\", \"case\", \"cast\", \"castle\", \"cause\", \"caused\", \"ceased\", \"certain\", \"certain\", \"chamber\", \"change\", \"changed\", \"character\", \"child\", \"children\", \"children\", \"circumstances\", \"city\", \"clear\", \"close\", \"closed\", \"cloud\", \"cold\", \"come\", \"coming\", \"common\", \"common\", \"companion\", \"company\", \"condition\", \"continued\", \"conversation\", \"corner\", \"corpse\", \"countenance\", \"country\", \"courage\", \"course\", \"covered\", \"creatures\", \"cried\", \"crowd\", \"curiosity\", \"cut\", \"danger\", \"dare\", \"dared\", \"dark\", \"darkness\", \"day\", \"days\", \"days\", \"days\", \"dead\", \"dear\", \"death\", \"deep\", \"degree\", \"delight\", \"departed\", \"deserted\", \"design\", \"desire\", \"despair\", \"despair\", \"despite\", \"did\", \"die\", \"died\", \"different\", \"difficulty\", \"discovered\", \"discovery\", \"disease\", \"distance\", \"distinct\", \"does\", \"dog\", \"dont\", \"door\", \"door\", \"doubt\", \"dr\", \"dream\", \"dreams\", \"drew\", \"dupin\", \"early\", \"ears\", \"earth\", \"earth\", \"easily\", \"effect\", \"elizabeth\", \"end\", \"endeavoured\", \"england\", \"english\", \"entered\", \"entire\", \"entirely\", \"escape\", \"especially\", \"evening\", \"events\", \"evidence\", \"evident\", \"evidently\", \"evil\", \"example\", \"exceedingly\", \"excited\", \"existence\", \"expected\", \"expression\", \"extent\", \"eye\", \"eyes\", \"eyes\", \"face\", \"face\", \"faces\", \"fact\", \"failed\", \"faint\", \"fall\", \"fallen\", \"family\", \"fancy\", \"far\", \"farther\", \"fate\", \"father\", \"father\", \"fear\", \"fearful\", \"features\", \"feel\", \"feel\", \"feeling\", \"feeling\", \"feeling\", \"feelings\", \"feet\", \"fell\", \"fellow\", \"fellow\", \"fellow\", \"felt\", \"figure\", \"filled\", \"finally\", \"fine\", \"fixed\", \"fled\", \"floor\", \"flowers\", \"followed\", \"following\", \"force\", \"forced\", \"forest\", \"forever\", \"forgotten\", \"form\", \"formed\", \"forms\", \"forth\", \"frame\", \"fresh\", \"friend\", \"friends\", \"frightful\", \"fully\", \"gave\", \"general\", \"gentle\", \"gentle\", \"gentle\", \"gentleman\", \"ghastly\", \"gilman\", \"girl\", \"given\", \"given\", \"giving\", \"glass\", \"god\", \"gods\", \"going\", \"gold\", \"gone\", \"good\", \"got\", \"gradually\", \"grave\", \"great\", \"greater\", \"greatest\", \"green\", \"grew\", \"grief\", \"ground\", \"ground\", \"hair\", \"half\", \"hand\", \"hands\", \"happened\", \"happiness\", \"happy\", \"happy\", \"hardly\", \"having\", \"head\", \"head\", \"health\", \"heard\", \"heart\", \"heart\", \"heart\", \"heaven\", \"height\", \"held\", \"help\", \"hideous\", \"high\", \"high\", \"hill\", \"hills\", \"home\", \"hope\", \"hopes\", \"horizon\", \"horrible\", \"horror\", \"hour\", \"hours\", \"house\", \"houses\", \"huge\", \"human\", \"hung\", \"ice\", \"idea\", \"ideas\", \"idris\", \"ill\", \"imagination\", \"immediate\", \"immediately\", \"immediately\", \"impossible\", \"impression\", \"increased\", \"individual\", \"influence\", \"innsmouth\", \"instance\", \"instant\", \"intense\", \"island\", \"joy\", \"just\", \"kept\", \"kind\", \"knew\", \"know\", \"knowledge\", \"known\", \"lady\", \"land\", \"language\", \"large\", \"late\", \"later\", \"lay\", \"lay\", \"leave\", \"led\", \"left\", \"length\", \"let\", \"letter\", \"life\", \"light\", \"like\", \"like\", \"limbs\", \"line\", \"lips\", \"listened\", \"little\", \"little\", \"live\", \"lived\", \"living\", \"living\", \"living\", \"london\", \"london\", \"long\", \"longer\", \"longer\", \"look\", \"looked\", \"looking\", \"looking\", \"lord\", \"lost\", \"love\", \"loved\", \"lovely\", \"low\", \"low\", \"machine\", \"mad\", \"madame\", \"main\", \"make\", \"making\", \"man\", \"manner\", \"marble\", \"marked\", \"matter\", \"mean\", \"means\", \"memory\", \"men\", \"mentioned\", \"mere\", \"merely\", \"met\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"minute\", \"minutes\", \"misery\", \"moment\", \"monstrous\", \"months\", \"moon\", \"morning\", \"mother\", \"motion\", \"motion\", \"mountain\", \"mountains\", \"mouth\", \"moved\", \"mr\", \"music\", \"narrow\", \"native\", \"natural\", \"natural\", \"nature\", \"nature\", \"near\", \"near\", \"nearly\", \"necessary\", \"need\", \"nervous\", \"new\", \"night\", \"north\", \"notice\", \"number\", \"object\", \"objects\", \"observed\", \"occurred\", \"ocean\", \"oclock\", \"odd\", \"oh\", \"oh\", \"old\", \"old\", \"open\", \"opened\", \"order\", \"ordinary\", \"outside\", \"pain\", \"palace\", \"pale\", \"paper\", \"party\", \"pass\", \"passage\", \"passed\", \"passed\", \"passion\", \"past\", \"peace\", \"peculiar\", \"peculiar\", \"peculiar\", \"people\", \"perceive\", \"perceived\", \"perdita\", \"perfect\", \"period\", \"period\", \"person\", \"persons\", \"place\", \"place\", \"place\", \"place\", \"placed\", \"plague\", \"plain\", \"pocket\", \"point\", \"poor\", \"portion\", \"position\", \"possessed\", \"possessed\", \"possible\", \"power\", \"presence\", \"presence\", \"present\", \"proceeded\", \"progress\", \"public\", \"purpose\", \"queer\", \"question\", \"quite\", \"rain\", \"ran\", \"rapidly\", \"raymond\", \"reached\", \"reached\", \"reached\", \"read\", \"real\", \"reality\", \"really\", \"reason\", \"received\", \"red\", \"regard\", \"remain\", \"remained\", \"remember\", \"remembered\", \"rendered\", \"replied\", \"resolved\", \"rest\", \"return\", \"returned\", \"rich\", \"right\", \"rise\", \"river\", \"road\", \"room\", \"round\", \"sad\", \"said\", \"sat\", \"sat\", \"save\", \"saw\", \"saw\", \"saw\", \"saw\", \"saw\", \"saw\", \"say\", \"says\", \"scarcely\", \"scene\", \"sea\", \"sea\", \"search\", \"second\", \"secret\", \"seek\", \"seen\", \"seized\", \"self\", \"sense\", \"sent\", \"sentiment\", \"set\", \"set\", \"shadow\", \"shall\", \"shewed\", \"ship\", \"shore\", \"short\", \"sight\", \"sight\", \"sight\", \"sight\", \"silence\", \"silent\", \"simple\", \"single\", \"singular\", \"sir\", \"sister\", \"sky\", \"sleep\", \"slept\", \"slight\", \"slowly\", \"small\", \"society\", \"sole\", \"solitude\", \"somewhat\", \"soon\", \"sort\", \"sought\", \"soul\", \"soul\", \"soul\", \"soul\", \"sound\", \"sounds\", \"south\", \"space\", \"speak\", \"spent\", \"spirit\", \"spirits\", \"spoke\", \"spot\", \"spot\", \"spring\", \"st\", \"stars\", \"started\", \"state\", \"steps\", \"stone\", \"stood\", \"story\", \"strange\", \"strange\", \"street\", \"strength\", \"struck\", \"subject\", \"succeeded\", \"success\", \"suddenly\", \"suffered\", \"sufficient\", \"sufficiently\", \"summer\", \"sun\", \"sun\", \"sun\", \"suppose\", \"supposed\", \"sure\", \"sure\", \"surface\", \"sweet\", \"sweet\", \"sympathy\", \"table\", \"taken\", \"taking\", \"tale\", \"tall\", \"tears\", \"tell\", \"tell\", \"terrible\", \"terror\", \"thee\", \"thing\", \"things\", \"things\", \"think\", \"thou\", \"thought\", \"thoughts\", \"thousand\", \"threw\", \"thrown\", \"thy\", \"till\", \"till\", \"till\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"times\", \"told\", \"tomb\", \"took\", \"town\", \"town\", \"tree\", \"trees\", \"tried\", \"true\", \"truth\", \"turn\", \"turned\", \"uncle\", \"understand\", \"unknown\", \"upper\", \"use\", \"usual\", \"utter\", \"utterly\", \"vain\", \"various\", \"vast\", \"view\", \"visible\", \"visible\", \"vision\", \"visit\", \"voice\", \"wall\", \"walls\", \"want\", \"watched\", \"water\", \"waters\", \"way\", \"week\", \"weight\", \"went\", \"west\", \"whilst\", \"white\", \"wholly\", \"wide\", \"wife\", \"wild\", \"wind\", \"window\", \"windows\", \"windsor\", \"winter\", \"wish\", \"wished\", \"woman\", \"wonder\", \"woods\", \"word\", \"words\", \"work\", \"world\", \"write\", \"ye\", \"year\", \"years\", \"years\", \"yes\", \"young\", \"youth\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [8, 12, 6, 18, 20, 10, 1, 7, 17, 11, 9, 2, 19, 14, 15, 13, 4, 16, 3, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el110603613073526892202609\", ldavis_el110603613073526892202609_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el110603613073526892202609\", ldavis_el110603613073526892202609_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el110603613073526892202609\", ldavis_el110603613073526892202609_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.sklearn\n",
    "vis_data=pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic model evaluation\n",
    "You can evaluate LDA models using Coherence measurement, and visualize the final result using PyLDAvis. A set of statements or facts is said to be coherent, if they support each other.\n",
    "\n",
    "The most common way to evaluate a probabilistic model is to measure the log-likelihood of a held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -335395.6175410904\n",
      "Perplexity:  9826.661252001102\n",
      "{'batch_size': 128, 'doc_topic_prior': None, 'evaluate_every': -1, 'learning_decay': 0.7, 'learning_method': 'online', 'learning_offset': 50.0, 'max_doc_update_iter': 100, 'max_iter': 5, 'mean_change_tol': 0.001, 'n_components': 20, 'n_jobs': None, 'perp_tol': 0.1, 'random_state': 0, 'topic_word_prior': None, 'total_samples': 1000000.0, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda.score(tfidf))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda.perplexity(tfidf))\n",
    "\n",
    "# See model parameters\n",
    "print(lda.get_params())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
